{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:04.333461Z","iopub.status.busy":"2022-11-23T08:38:04.333057Z","iopub.status.idle":"2022-11-23T08:38:23.723267Z","shell.execute_reply":"2022-11-23T08:38:23.721420Z","shell.execute_reply.started":"2022-11-23T08:38:04.333384Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.7.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","try:\n","    from torchinfo import summary\n","except ModuleNotFoundError:\n","    !pip install torchinfo\n","    from torchinfo import summary\n","\n","import os\n","import pathlib\n","import shutil\n","import sys"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:23.731868Z","iopub.status.busy":"2022-11-23T08:38:23.730661Z","iopub.status.idle":"2022-11-23T08:38:23.757096Z","shell.execute_reply":"2022-11-23T08:38:23.754979Z","shell.execute_reply.started":"2022-11-23T08:38:23.731815Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nSame dir structure as on Kaggle\\ninput/\\n    lfw-dataset/\\n        csv files\\n        lfw-deepfunneled/\\nworking/\\n    notebook\\n    data/\\n        train/\\n        val/\\n        test/\\n'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Same dir structure as on Kaggle\n","input/\n","    lfw-dataset/\n","        csv files\n","        lfw-deepfunneled/\n","working/\n","    notebook\n","    data/\n","        train/\n","        val/\n","        test/\n","\"\"\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:23.759491Z","iopub.status.busy":"2022-11-23T08:38:23.758774Z","iopub.status.idle":"2022-11-23T08:38:23.913700Z","shell.execute_reply":"2022-11-23T08:38:23.912528Z","shell.execute_reply.started":"2022-11-23T08:38:23.759453Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)\n","\n","# https://towardsdatascience.com/pytorch-switching-to-the-gpu-a7c0b21e8a99\n","# for modifications to use GPU\n","\n","# Also this: https://github.com/pytorch/examples/blob/main/imagenet/main.py"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:23.920285Z","iopub.status.busy":"2022-11-23T08:38:23.919596Z","iopub.status.idle":"2022-11-23T08:38:23.928879Z","shell.execute_reply":"2022-11-23T08:38:23.927718Z","shell.execute_reply.started":"2022-11-23T08:38:23.920214Z"},"trusted":true},"outputs":[],"source":["data_folder = '../input/lfw-dataset/'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:23.936308Z","iopub.status.busy":"2022-11-23T08:38:23.933149Z","iopub.status.idle":"2022-11-23T08:38:24.040633Z","shell.execute_reply":"2022-11-23T08:38:24.039324Z","shell.execute_reply.started":"2022-11-23T08:38:23.936266Z"},"trusted":true},"outputs":[],"source":["lfw_allnames = pd.read_csv(data_folder+\"lfw_allnames.csv\")\n","\n","image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\n","image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\n","image_paths['image_path'] = image_paths.image_path.apply(lambda x: str(x).zfill(4))\n","image_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\n","image_paths = image_paths.drop(\"images\", axis=1)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:24.051501Z","iopub.status.busy":"2022-11-23T08:38:24.049351Z","iopub.status.idle":"2022-11-23T08:38:24.082589Z","shell.execute_reply":"2022-11-23T08:38:24.081601Z","shell.execute_reply.started":"2022-11-23T08:38:24.051459Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["George_W_Bush        530\n","Colin_Powell         236\n","Tony_Blair           144\n","Donald_Rumsfeld      121\n","Gerhard_Schroeder    109\n","Ariel_Sharon          77\n","Hugo_Chavez           71\n","Junichiro_Koizumi     60\n","Jean_Chretien         55\n","John_Ashcroft         53\n","Name: name, dtype: int64\n","['George_W_Bush', 'Colin_Powell', 'Tony_Blair', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Ariel_Sharon', 'Hugo_Chavez', 'Junichiro_Koizumi', 'Jean_Chretien', 'John_Ashcroft'] [530, 236, 144, 121, 109, 77, 71, 60, 55, 53]\n"]}],"source":["num_ppl = 10\n","\n","print(image_paths['name'].value_counts()[:num_ppl])\n","list_people = list(image_paths['name'].value_counts()[:num_ppl].keys())\n","list_num_images = list(image_paths['name'].value_counts()[:num_ppl])\n","print(list_people, list_num_images)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:24.089803Z","iopub.status.busy":"2022-11-23T08:38:24.087334Z","iopub.status.idle":"2022-11-23T08:38:24.100277Z","shell.execute_reply":"2022-11-23T08:38:24.099182Z","shell.execute_reply.started":"2022-11-23T08:38:24.089764Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\nnum_for_each = image_paths['name'].value_counts()[num_ppl-1]\\ntmp_l = []\\nfor name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\\n    tmp_l.append(image_paths[image_paths.name==name].sample(num_for_each))\\ndata = pd.concat(tmp_l)\\nprint(data)\\n\""]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","num_for_each = image_paths['name'].value_counts()[num_ppl-1]\n","tmp_l = []\n","for name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\n","    tmp_l.append(image_paths[image_paths.name==name].sample(num_for_each))\n","data = pd.concat(tmp_l)\n","print(data)\n","\"\"\""]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:24.106130Z","iopub.status.busy":"2022-11-23T08:38:24.105459Z","iopub.status.idle":"2022-11-23T08:38:24.165460Z","shell.execute_reply":"2022-11-23T08:38:24.164573Z","shell.execute_reply.started":"2022-11-23T08:38:24.106094Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(330, 2) (90, 2) (110, 2)\n"]}],"source":["num_for_each = image_paths['name'].value_counts()[num_ppl-1]\n","tmp_train = []\n","tmp_val = []\n","tmp_test = []\n","for name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\n","    data_all = image_paths[image_paths.name==name].sample(num_for_each)\n","    data_train, data_test = train_test_split(data_all, test_size=0.2)\n","    data_train, data_val = train_test_split(data_train, test_size=0.2)\n","    tmp_train.append(data_train.copy())\n","    tmp_val.append(data_val.copy())\n","    tmp_test.append(data_test.copy())\n","data_train = pd.concat(tmp_train)\n","data_val = pd.concat(tmp_val)\n","data_test = pd.concat(tmp_test)\n","print(data_train.shape, data_val.shape, data_test.shape)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:24.172188Z","iopub.status.busy":"2022-11-23T08:38:24.169805Z","iopub.status.idle":"2022-11-23T08:38:33.013123Z","shell.execute_reply":"2022-11-23T08:38:33.012105Z","shell.execute_reply.started":"2022-11-23T08:38:24.172153Z"},"trusted":true},"outputs":[],"source":["data_root = './data/'\n","\n","data_list = [data_train, data_val, data_test]\n","dirs = ['train', 'val', 'test']\n","\n","# \"\"\"             # (un)comment this line (only) and run, to copy\n","\n","# # remove data directory if it exists\n","if os.path.exists(data_root) and os.path.isdir(data_root):\n","    shutil.rmtree(data_root)\n","\n","transform_augment = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=1)\n","])\n","\n","for i in range(len(dirs)):\n","    pathlib.Path(os.path.join(data_root, dirs[i])).mkdir(parents=True, exist_ok=True)\n","    \n","    data = data_list[i]\n","\n","    for person in list_people:\n","        if len(data_train[data_train['name']==person])>0:\n","            pathlib.Path(os.path.join(data_root, dirs[i], person)).mkdir(parents=True, exist_ok=True)\n","\n","    for im_path in data_list[i].image_path:\n","        name = data[data['image_path']==im_path]['name'].iloc[0]\n","        path_from = os.path.join(data_folder+'/lfw-deepfunneled/lfw-deepfunneled/', im_path)\n","        filename, file_extension = os.path.splitext(path_from.split('/')[-1])\n","        path_to = os.path.join(data_root, dirs[i], name)\n","\n","        if not os.path.isfile(os.path.join(path_to, im_path)):\n","            shutil.copy(path_from, path_to)         # earlier (just copies image)\n","            \n","            # if dirs[i]!='test':                   # test-time augmentation too?\n","            img = Image.open(path_from)\n","            img = transform_augment(img)            # transformed image\n","            img.save(path_to+'/'+filename+'_transformed'+file_extension)\n","\n","# \"\"\""]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:33.017477Z","iopub.status.busy":"2022-11-23T08:38:33.017124Z","iopub.status.idle":"2022-11-23T08:38:33.033764Z","shell.execute_reply":"2022-11-23T08:38:33.032840Z","shell.execute_reply.started":"2022-11-23T08:38:33.017449Z"},"trusted":true},"outputs":[],"source":["train_path = os.path.join(data_root, dirs[0])\n","val_path = os.path.join(data_root, dirs[1])\n","test_path = os.path.join(data_root, dirs[2])\n","\n","train_transform = transforms.Compose(transforms=[\n","    # transforms.RandomHorizontalFlip(),\n","    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=0, std=255),      # output = (input-mean)/std\n","])\n","test_transform = transforms.Compose(transforms=[\n","    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=0, std=255)\n","])\n","\n","dataloader_kwargs = {\n","    'pin_memory': True,\n","    'num_workers': 1,\n","    'batch_size': 1,\n","    'shuffle': True\n","}\n","non_blocking = dataloader_kwargs['pin_memory']  # https://stackoverflow.com/questions/55563376/\n","\n","train_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(train_path, train_transform), **dataloader_kwargs\n",")\n","val_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(val_path, test_transform), **dataloader_kwargs\n",")\n","test_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(test_path, test_transform), **dataloader_kwargs\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:33.035627Z","iopub.status.busy":"2022-11-23T08:38:33.035364Z","iopub.status.idle":"2022-11-23T08:38:37.707421Z","shell.execute_reply":"2022-11-23T08:38:37.706078Z","shell.execute_reply.started":"2022-11-23T08:38:33.035603Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3, 250, 250]) torch.Size([1])\n","tensor(0.5311)\n"]}],"source":["for data in train_loader:\n","    print(data[0].shape, data[1].shape)\n","    # print(data[0], data[1])\n","    print(torch.mean(data[0]))\n","    break\n","# Total train data is of shape (128, 3, 250, 250)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:37.709437Z","iopub.status.busy":"2022-11-23T08:38:37.709007Z","iopub.status.idle":"2022-11-23T08:38:37.721187Z","shell.execute_reply":"2022-11-23T08:38:37.719904Z","shell.execute_reply.started":"2022-11-23T08:38:37.709400Z"},"trusted":true},"outputs":[],"source":["class FaceCNN_initial(nn.Module):\n","    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n","        super().__init__()\n","\n","        self.network = nn.Sequential(\n","\n","        nn.Conv2d(in_channels=num_input_channels, out_channels=50, kernel_size=3, stride=stride, padding=padding),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","\n","        nn.Conv2d(in_channels=50, out_channels=20, kernel_size=3, stride=stride, padding=padding),\n","        nn.ReLU(),\n","\n","        nn.Flatten(),\n","        nn.Linear(in_features=20*125*125, out_features=num_classes)\n","\n","        )\n","\n","    def forward(self, input):\n","        output = self.network(input)\n","        return output"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:37.723026Z","iopub.status.busy":"2022-11-23T08:38:37.722635Z","iopub.status.idle":"2022-11-23T08:38:37.734861Z","shell.execute_reply":"2022-11-23T08:38:37.733750Z","shell.execute_reply.started":"2022-11-23T08:38:37.722998Z"},"trusted":true},"outputs":[],"source":["class FaceCNN(nn.Module):\n","    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n","        super().__init__()\n","\n","        self.network = nn.Sequential(\n","\n","            # (250, 250, 3)\n","\n","            nn.Conv2d(in_channels=num_input_channels, out_channels=64, kernel_size=7, stride=2, padding=padding),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=padding),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=stride, padding=padding),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=stride, padding=padding),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Flatten(),\n","            nn.Linear(in_features=14400, out_features=1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),    # https://stats.stackexchange.com/questions/240305/\n","            nn.Linear(in_features=1024, out_features=64),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),\n","            nn.Linear(in_features=64, out_features=num_classes),\n","\n","        )\n","\n","    def forward(self, input):\n","        output = self.network(input)\n","        return output"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:37.737155Z","iopub.status.busy":"2022-11-23T08:38:37.736448Z","iopub.status.idle":"2022-11-23T08:38:48.587287Z","shell.execute_reply":"2022-11-23T08:38:48.586171Z","shell.execute_reply.started":"2022-11-23T08:38:37.737116Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","FaceCNN                                  [1, 10]                   --\n","├─Sequential: 1-1                        [1, 10]                   --\n","│    └─Conv2d: 2-1                       [1, 64, 123, 123]         9,472\n","│    └─BatchNorm2d: 2-2                  [1, 64, 123, 123]         128\n","│    └─ReLU: 2-3                         [1, 64, 123, 123]         --\n","│    └─MaxPool2d: 2-4                    [1, 64, 61, 61]           --\n","│    └─Dropout: 2-5                      [1, 64, 61, 61]           --\n","│    └─Conv2d: 2-6                       [1, 128, 61, 61]          73,856\n","│    └─BatchNorm2d: 2-7                  [1, 128, 61, 61]          256\n","│    └─ReLU: 2-8                         [1, 128, 61, 61]          --\n","│    └─MaxPool2d: 2-9                    [1, 128, 30, 30]          --\n","│    └─Dropout: 2-10                     [1, 128, 30, 30]          --\n","│    └─Conv2d: 2-11                      [1, 256, 30, 30]          295,168\n","│    └─BatchNorm2d: 2-12                 [1, 256, 30, 30]          512\n","│    └─ReLU: 2-13                        [1, 256, 30, 30]          --\n","│    └─MaxPool2d: 2-14                   [1, 256, 15, 15]          --\n","│    └─Dropout: 2-15                     [1, 256, 15, 15]          --\n","│    └─Conv2d: 2-16                      [1, 64, 15, 15]           147,520\n","│    └─BatchNorm2d: 2-17                 [1, 64, 15, 15]           128\n","│    └─ReLU: 2-18                        [1, 64, 15, 15]           --\n","│    └─Dropout: 2-19                     [1, 64, 15, 15]           --\n","│    └─Flatten: 2-20                     [1, 14400]                --\n","│    └─Linear: 2-21                      [1, 1024]                 14,746,624\n","│    └─ReLU: 2-22                        [1, 1024]                 --\n","│    └─Dropout: 2-23                     [1, 1024]                 --\n","│    └─Linear: 2-24                      [1, 64]                   65,600\n","│    └─ReLU: 2-25                        [1, 64]                   --\n","│    └─Dropout: 2-26                     [1, 64]                   --\n","│    └─Linear: 2-27                      [1, 10]                   650\n","==========================================================================================\n","Total params: 15,339,914\n","Trainable params: 15,339,914\n","Non-trainable params: 0\n","Total mult-adds (M): 731.78\n","==========================================================================================\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 27.04\n","Params size (MB): 61.36\n","Estimated Total Size (MB): 89.15\n","==========================================================================================\n"]}],"source":["num_input_channels = 3\n","model = FaceCNN(num_input_channels=num_input_channels, num_classes=len(list_people)).to(device)\n","# for e in model.parameters():\n","#     print(e)\n","print(summary(model, input_size=(dataloader_kwargs['batch_size'], num_input_channels, 250, 250)))\n","\n","# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","num_epochs = 30"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:48.594490Z","iopub.status.busy":"2022-11-23T08:38:48.592298Z","iopub.status.idle":"2022-11-23T08:38:48.602958Z","shell.execute_reply":"2022-11-23T08:38:48.601684Z","shell.execute_reply.started":"2022-11-23T08:38:48.594446Z"},"trusted":true},"outputs":[],"source":["def evaluate(loader, model):\n","\n","    model.eval()\n","\n","    score = 0\n","    cnt = 0\n","\n","    with torch.no_grad():       # not training, so no need to calculate gradients\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","            output = model(inputs)\n","            _, pred = torch.max(output.data, 1)\n","            score += float(torch.sum(pred==labels.data))\n","            cnt += data[0].shape[0]\n","\n","    return score/cnt"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:48.607066Z","iopub.status.busy":"2022-11-23T08:38:48.605773Z","iopub.status.idle":"2022-11-23T08:38:48.624410Z","shell.execute_reply":"2022-11-23T08:38:48.623288Z","shell.execute_reply.started":"2022-11-23T08:38:48.607023Z"},"trusted":true},"outputs":[],"source":["def train():\n","    best_acc = 0.0\n","    \n","    for epoch in range(num_epochs):\n","        train_score = 0\n","        cnt = 0\n","        train_loss = 0\n","\n","        model.train()\n","        \n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","\n","            optimizer.zero_grad()\n","            \n","            outputs = model(inputs)\n","            \n","            # print(outputs, labels)\n","\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            train_loss += loss.item()\n","\n","            _, preds = torch.max(outputs.data, 1)\n","            train_score += float(torch.sum(preds==labels.data))\n","            cnt += inputs.shape[0]\n","\n","            # print(preds, labels)\n","\n","        train_acc = train_score/cnt\n","        val_acc = evaluate(val_loader, model)\n","        \n","        print(\"Epoch:\", epoch, \"\\tLoss:\", train_loss, \"\\tTraining Acc:\", train_acc, \"\\tVal Acc:\", val_acc)\n","\n","        if val_acc > best_acc:\n","            torch.save(model.state_dict(),'best.model')\n","            best_acc = val_acc"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:38:48.632069Z","iopub.status.busy":"2022-11-23T08:38:48.629064Z","iopub.status.idle":"2022-11-23T08:42:37.297827Z","shell.execute_reply":"2022-11-23T08:42:37.296471Z","shell.execute_reply.started":"2022-11-23T08:38:48.632028Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tLoss: 1528.9663017988205 \tTraining Acc: 0.09242424242424242 \tVal Acc: 0.11666666666666667\n","Epoch: 1 \tLoss: 1502.679721236229 \tTraining Acc: 0.15757575757575756 \tVal Acc: 0.2111111111111111\n","Epoch: 2 \tLoss: 1463.5338008403778 \tTraining Acc: 0.1621212121212121 \tVal Acc: 0.26666666666666666\n","Epoch: 3 \tLoss: 1372.7203063964844 \tTraining Acc: 0.25303030303030305 \tVal Acc: 0.37777777777777777\n","Epoch: 4 \tLoss: 1244.0758409798145 \tTraining Acc: 0.32727272727272727 \tVal Acc: 0.4222222222222222\n","Epoch: 5 \tLoss: 1121.3936377167702 \tTraining Acc: 0.36363636363636365 \tVal Acc: 0.4222222222222222\n","Epoch: 6 \tLoss: 1009.2355154734105 \tTraining Acc: 0.4303030303030303 \tVal Acc: 0.5\n","Epoch: 7 \tLoss: 912.3891499266028 \tTraining Acc: 0.4666666666666667 \tVal Acc: 0.5666666666666667\n","Epoch: 8 \tLoss: 802.6440292969346 \tTraining Acc: 0.5545454545454546 \tVal Acc: 0.6444444444444445\n","Epoch: 9 \tLoss: 735.3432892244309 \tTraining Acc: 0.5696969696969697 \tVal Acc: 0.65\n","Epoch: 10 \tLoss: 666.9478785937536 \tTraining Acc: 0.6212121212121212 \tVal Acc: 0.6611111111111111\n","Epoch: 11 \tLoss: 591.0443014791235 \tTraining Acc: 0.6818181818181818 \tVal Acc: 0.6388888888888888\n","Epoch: 12 \tLoss: 496.5321105477051 \tTraining Acc: 0.7257575757575757 \tVal Acc: 0.6722222222222223\n","Epoch: 13 \tLoss: 446.6869826923589 \tTraining Acc: 0.7560606060606061 \tVal Acc: 0.7111111111111111\n","Epoch: 14 \tLoss: 367.4004441020443 \tTraining Acc: 0.8272727272727273 \tVal Acc: 0.7611111111111111\n","Epoch: 15 \tLoss: 322.6218070056166 \tTraining Acc: 0.8318181818181818 \tVal Acc: 0.7722222222222223\n","Epoch: 16 \tLoss: 297.68052879207244 \tTraining Acc: 0.853030303030303 \tVal Acc: 0.6388888888888888\n","Epoch: 17 \tLoss: 240.15884953091881 \tTraining Acc: 0.8636363636363636 \tVal Acc: 0.7777777777777778\n","Epoch: 18 \tLoss: 223.34118653787618 \tTraining Acc: 0.8833333333333333 \tVal Acc: 0.8222222222222222\n","Epoch: 19 \tLoss: 195.8165926825177 \tTraining Acc: 0.9015151515151515 \tVal Acc: 0.75\n","Epoch: 20 \tLoss: 174.60090274833294 \tTraining Acc: 0.9196969696969697 \tVal Acc: 0.7944444444444444\n","Epoch: 21 \tLoss: 139.5507349503913 \tTraining Acc: 0.9348484848484848 \tVal Acc: 0.8555555555555555\n","Epoch: 22 \tLoss: 146.09908531672738 \tTraining Acc: 0.9272727272727272 \tVal Acc: 0.8111111111111111\n","Epoch: 23 \tLoss: 109.12153381752239 \tTraining Acc: 0.9484848484848485 \tVal Acc: 0.8111111111111111\n","Epoch: 24 \tLoss: 99.60142870776207 \tTraining Acc: 0.956060606060606 \tVal Acc: 0.85\n","Epoch: 25 \tLoss: 93.80636242912291 \tTraining Acc: 0.9590909090909091 \tVal Acc: 0.8555555555555555\n","Epoch: 26 \tLoss: 74.04265433399226 \tTraining Acc: 0.9696969696969697 \tVal Acc: 0.8777777777777778\n","Epoch: 27 \tLoss: 91.88863193862318 \tTraining Acc: 0.9575757575757575 \tVal Acc: 0.8333333333333334\n","Epoch: 28 \tLoss: 60.1019510711011 \tTraining Acc: 0.9681818181818181 \tVal Acc: 0.8444444444444444\n","Epoch: 29 \tLoss: 62.56993119053227 \tTraining Acc: 0.9681818181818181 \tVal Acc: 0.8555555555555555\n"]}],"source":["train()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T08:45:46.081304Z","iopub.status.busy":"2022-11-23T08:45:46.080896Z","iopub.status.idle":"2022-11-23T08:45:47.454066Z","shell.execute_reply":"2022-11-23T08:45:47.452918Z","shell.execute_reply.started":"2022-11-23T08:45:46.081256Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.7454545454545455\n"]}],"source":["model.load_state_dict(torch.load('best.model'))\n","model.eval()\n","score = 0\n","cnt = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        output = model(inputs)\n","        _, pred = torch.max(output.data, 1)\n","        score += float(torch.sum(pred==labels.data))\n","        cnt += data[0].shape[0]\n","\n","print(score/cnt)"]},{"cell_type":"markdown","metadata":{},"source":["### Train Stats\n","\n","```\n","num_ppl=4, num_for_each=100, num_input_channels=3, SGD\n","\n","Epoch: 0 \tLoss: 358.62260937690735 \tTraining Acc: 0.3046875 \tVal Acc: 0.390625\n","Epoch: 1 \tLoss: 333.57504665851593 \tTraining Acc: 0.4453125 \tVal Acc: 0.5\n","Epoch: 2 \tLoss: 287.8054849989712 \tTraining Acc: 0.53515625 \tVal Acc: 0.484375\n","Epoch: 3 \tLoss: 214.57957464270294 \tTraining Acc: 0.66796875 \tVal Acc: 0.546875\n","Epoch: 4 \tLoss: 128.76155146129895 \tTraining Acc: 0.8515625 \tVal Acc: 0.6875\n","Epoch: 5 \tLoss: 66.8646472900873 \t    Training Acc: 0.9375 \t    Val Acc: 0.609375\n","Epoch: 6 \tLoss: 38.552940751942515 \tTraining Acc: 0.96484375 \tVal Acc: 0.65625\n","Epoch: 7 \tLoss: 14.400232573081496 \tTraining Acc: 0.99609375 \tVal Acc: 0.640625\n","Epoch: 8 \tLoss: 6.6097561110264 \t    Training Acc: 1.0 \t        Val Acc: 0.71875\n","Epoch: 9 \tLoss: 3.2570621859687208 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\n","Epoch: 10 \tLoss: 2.2477716574980775 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\n","Epoch: 11 \tLoss: 1.6625592309815147 \tTraining Acc: 1.0 \t        Val Acc: 0.734375\n","Epoch: 12 \tLoss: 1.2643641760919024 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\n","Epoch: 13 \tLoss: 1.0747595029670762 \tTraining Acc: 1.0 \t        Val Acc: 0.71875\n","Epoch: 14 \tLoss: 0.8993665239690074 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\n","\n","Test Acc: 0.85\n","```\n","<hr>\n","\n","```\n","Larger network: num_ppl=25, num_for_each=33, num_input_channels=3, SGD, dropout=0.5, no dropout after conv layers\n","\n","Epoch: 0 \tLoss: 1701.3236393928528 \tTraining Acc: 0.05113636363636364 \tVal Acc: 0.08333333333333333\n","Epoch: 1 \tLoss: 1648.1168529987335 \tTraining Acc: 0.08143939393939394 \tVal Acc: 0.13636363636363635\n","Epoch: 2 \tLoss: 1570.683046221733 \tTraining Acc: 0.11742424242424243 \tVal Acc: 0.16666666666666666\n","Epoch: 3 \tLoss: 1488.0452314019203 \tTraining Acc: 0.18181818181818182 \tVal Acc: 0.15151515151515152\n","Epoch: 4 \tLoss: 1359.583057552576 \tTraining Acc: 0.22348484848484848 \tVal Acc: 0.17424242424242425\n","Epoch: 5 \tLoss: 1259.4556982889771 \tTraining Acc: 0.3068181818181818 \tVal Acc: 0.25757575757575757\n","Epoch: 6 \tLoss: 1127.6610003113747 \tTraining Acc: 0.3712121212121212 \tVal Acc: 0.2727272727272727\n","Epoch: 7 \tLoss: 1039.084867735859 \tTraining Acc: 0.4090909090909091 \tVal Acc: 0.3333333333333333\n","Epoch: 8 \tLoss: 917.1557948449627 \tTraining Acc: 0.4791666666666667 \tVal Acc: 0.2878787878787879\n","Epoch: 9 \tLoss: 827.8774750904413 \tTraining Acc: 0.571969696969697 \tVal Acc: 0.45454545454545453\n","Epoch: 10 \tLoss: 673.7398463344434 \tTraining Acc: 0.615530303030303 \tVal Acc: 0.38636363636363635\n","Epoch: 11 \tLoss: 606.598319072742 \tTraining Acc: 0.678030303030303 \tVal Acc: 0.4318181818181818\n","Epoch: 12 \tLoss: 502.92579286664113 \tTraining Acc: 0.7064393939393939 \tVal Acc: 0.44696969696969696\n","Epoch: 13 \tLoss: 412.34249426988936 \tTraining Acc: 0.7765151515151515 \tVal Acc: 0.45454545454545453\n","Epoch: 14 \tLoss: 329.6107653811632 \tTraining Acc: 0.8143939393939394 \tVal Acc: 0.5303030303030303\n","Epoch: 15 \tLoss: 263.91059577577107 \tTraining Acc: 0.8731060606060606 \tVal Acc: 0.5303030303030303\n","Epoch: 16 \tLoss: 248.08312809604558 \tTraining Acc: 0.8712121212121212 \tVal Acc: 0.4621212121212121\n","Epoch: 17 \tLoss: 197.47446866694008 \tTraining Acc: 0.9090909090909091 \tVal Acc: 0.5227272727272727\n","Epoch: 18 \tLoss: 172.28715605471052 \tTraining Acc: 0.9223484848484849 \tVal Acc: 0.5227272727272727\n","Epoch: 19 \tLoss: 133.61397156973908 \tTraining Acc: 0.9375 \tVal Acc: 0.5681818181818182\n","\n","Test Acc: 0.59\n","```\n","<hr>\n","\n","Lesser dropout, faster convergence (more fitting: 0.99 train acc, 0.58 val and test). Ofc not good always.\n","\n","<hr>\n","\n","```\n","Added dropout layers (p=0.2) after convolution: Train and val acc stay close for the first few (~10) epochs, but then diverge.\n","    30 epochs. Test acc: 0.38.\n","    50 epochs. Test acc: 0.55.\n","\n","Epoch: 0 \tLoss: 1706.7114553451538 \tTraining Acc: 0.05303030303030303 \tVal Acc: 0.06060606060606061\n","Epoch: 1 \tLoss: 1703.110694885254 \tTraining Acc: 0.045454545454545456 \tVal Acc: 0.06818181818181818\n","Epoch: 2 \tLoss: 1684.9260246753693 \tTraining Acc: 0.07196969696969698 \tVal Acc: 0.09090909090909091\n","Epoch: 3 \tLoss: 1654.7403428554535 \tTraining Acc: 0.06818181818181818 \tVal Acc: 0.12121212121212122\n","Epoch: 4 \tLoss: 1600.201600074768 \tTraining Acc: 0.11931818181818182 \tVal Acc: 0.1590909090909091\n","Epoch: 5 \tLoss: 1548.975799292326 \tTraining Acc: 0.13636363636363635 \tVal Acc: 0.11363636363636363\n","Epoch: 6 \tLoss: 1498.9787369072437 \tTraining Acc: 0.13446969696969696 \tVal Acc: 0.19696969696969696\n","Epoch: 7 \tLoss: 1436.561501070857 \tTraining Acc: 0.20643939393939395 \tVal Acc: 0.22727272727272727\n","Epoch: 8 \tLoss: 1384.87419853732 \tTraining Acc: 0.23863636363636365 \tVal Acc: 0.19696969696969696\n","Epoch: 9 \tLoss: 1319.722053207457 \tTraining Acc: 0.26136363636363635 \tVal Acc: 0.23484848484848486\n","Epoch: 10 \tLoss: 1251.95867273584 \tTraining Acc: 0.2859848484848485 \tVal Acc: 0.30303030303030304\n","Epoch: 11 \tLoss: 1211.6356632895768 \tTraining Acc: 0.29734848484848486 \tVal Acc: 0.25757575757575757\n","Epoch: 12 \tLoss: 1182.6897227037698 \tTraining Acc: 0.29734848484848486 \tVal Acc: 0.3181818181818182\n","Epoch: 13 \tLoss: 1113.2747115662205 \tTraining Acc: 0.3484848484848485 \tVal Acc: 0.29545454545454547\n","Epoch: 14 \tLoss: 1053.397371711675 \tTraining Acc: 0.3939393939393939 \tVal Acc: 0.3787878787878788\n","Epoch: 15 \tLoss: 958.3644631365314 \tTraining Acc: 0.4431818181818182 \tVal Acc: 0.3484848484848485\n","Epoch: 16 \tLoss: 938.4995879707858 \tTraining Acc: 0.4602272727272727 \tVal Acc: 0.36363636363636365\n","Epoch: 17 \tLoss: 866.5983875243692 \tTraining Acc: 0.48863636363636365 \tVal Acc: 0.4015151515151515\n","Epoch: 18 \tLoss: 822.6497887708247 \tTraining Acc: 0.5113636363636364 \tVal Acc: 0.3939393939393939\n","Epoch: 19 \tLoss: 782.9832759417477 \tTraining Acc: 0.5435606060606061 \tVal Acc: 0.3939393939393939\n","Epoch: 20 \tLoss: 698.3823288148269 \tTraining Acc: 0.5890151515151515 \tVal Acc: 0.3787878787878788\n","Epoch: 21 \tLoss: 658.3069786201813 \tTraining Acc: 0.6231060606060606 \tVal Acc: 0.4090909090909091\n","Epoch: 22 \tLoss: 569.9304089847283 \tTraining Acc: 0.634469696969697 \tVal Acc: 0.4393939393939394\n","Epoch: 23 \tLoss: 622.2785371405917 \tTraining Acc: 0.6420454545454546 \tVal Acc: 0.4772727272727273\n","Epoch: 24 \tLoss: 520.0580716890399 \tTraining Acc: 0.6761363636363636 \tVal Acc: 0.4696969696969697\n","Epoch: 25 \tLoss: 448.39510909226374 \tTraining Acc: 0.75 \tVal Acc: 0.45454545454545453\n","Epoch: 26 \tLoss: 429.5296724770451 \tTraining Acc: 0.759469696969697 \tVal Acc: 0.5\n","Epoch: 27 \tLoss: 380.9049152136067 \tTraining Acc: 0.7746212121212122 \tVal Acc: 0.5\n","Epoch: 28 \tLoss: 356.775621923327 \tTraining Acc: 0.8068181818181818 \tVal Acc: 0.5303030303030303\n","Epoch: 29 \tLoss: 363.29747000594216 \tTraining Acc: 0.7859848484848485 \tVal Acc: 0.4772727272727273\n","Epoch: 30 \tLoss: 297.8134929970547 \tTraining Acc: 0.8314393939393939 \tVal Acc: 0.5\n","Epoch: 31 \tLoss: 282.2684114029398 \tTraining Acc: 0.8541666666666666 \tVal Acc: 0.4621212121212121\n","Epoch: 32 \tLoss: 246.5776662196622 \tTraining Acc: 0.8522727272727273 \tVal Acc: 0.4696969696969697\n","Epoch: 33 \tLoss: 242.04962211154543 \tTraining Acc: 0.8560606060606061 \tVal Acc: 0.5\n","Epoch: 34 \tLoss: 208.3801038511872 \tTraining Acc: 0.8958333333333334 \tVal Acc: 0.5606060606060606\n","Epoch: 35 \tLoss: 194.5455155442314 \tTraining Acc: 0.8996212121212122 \tVal Acc: 0.5227272727272727\n","Epoch: 36 \tLoss: 158.61289137974723 \tTraining Acc: 0.9185606060606061 \tVal Acc: 0.5151515151515151\n","Epoch: 37 \tLoss: 162.71159709136646 \tTraining Acc: 0.9034090909090909 \tVal Acc: 0.5\n","Epoch: 38 \tLoss: 170.97251973819846 \tTraining Acc: 0.9015151515151515 \tVal Acc: 0.5075757575757576\n","Epoch: 39 \tLoss: 157.24092914579478 \tTraining Acc: 0.9147727272727273 \tVal Acc: 0.553030303030303\n","Epoch: 40 \tLoss: 133.82072701480678 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5\n","Epoch: 41 \tLoss: 136.39509819635964 \tTraining Acc: 0.928030303030303 \tVal Acc: 0.553030303030303\n","Epoch: 42 \tLoss: 126.88825436101558 \tTraining Acc: 0.9318181818181818 \tVal Acc: 0.5075757575757576\n","Epoch: 43 \tLoss: 124.5683646489997 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5757575757575758\n","Epoch: 44 \tLoss: 120.55329895571163 \tTraining Acc: 0.9337121212121212 \tVal Acc: 0.5\n","Epoch: 45 \tLoss: 100.53747285808356 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5378787878787878\n","Epoch: 46 \tLoss: 92.43336634917796 \tTraining Acc: 0.9621212121212122 \tVal Acc: 0.5606060606060606\n","Epoch: 47 \tLoss: 84.71885716843988 \tTraining Acc: 0.9564393939393939 \tVal Acc: 0.5303030303030303\n","Epoch: 48 \tLoss: 80.6087966322365 \tTraining Acc: 0.9602272727272727 \tVal Acc: 0.5227272727272727\n","Epoch: 49 \tLoss: 86.07536707191636 \tTraining Acc: 0.9564393939393939 \tVal Acc: 0.5378787878787878\n","```\n","\n","<hr>\n","\n","Batch size 50: Train accuracy 4% even after 50 epochs. (25 ppl)\n","\n","<hr>\n","\n","Data Augmentation. Horizontal flipping: 37% test acc after 10 epochs. (25 ppl)\n","\n","```\n","Epoch: 0 \tLoss: 3413.37361741066 \tTraining Acc: 0.041666666666666664 \tVal Acc: 0.022727272727272728\n","Epoch: 1 \tLoss: 3346.7614665031433 \tTraining Acc: 0.07196969696969698 \tVal Acc: 0.05303030303030303\n","Epoch: 2 \tLoss: 3201.3032276034355 \tTraining Acc: 0.09753787878787878 \tVal Acc: 0.10606060606060606\n","Epoch: 3 \tLoss: 3079.741751715541 \tTraining Acc: 0.12973484848484848 \tVal Acc: 0.125\n","Epoch: 4 \tLoss: 2865.667134359479 \tTraining Acc: 0.17518939393939395 \tVal Acc: 0.18181818181818182\n","Epoch: 5 \tLoss: 2718.3486230820417 \tTraining Acc: 0.19412878787878787 \tVal Acc: 0.19696969696969696\n","Epoch: 6 \tLoss: 2579.4593008980155 \tTraining Acc: 0.22443181818181818 \tVal Acc: 0.25\n","Epoch: 7 \tLoss: 2391.6380325537175 \tTraining Acc: 0.29829545454545453 \tVal Acc: 0.30303030303030304\n","Epoch: 8 \tLoss: 2201.1669663584325 \tTraining Acc: 0.3484848484848485 \tVal Acc: 0.23863636363636365\n","Epoch: 9 \tLoss: 2032.1635219482705 \tTraining Acc: 0.38920454545454547 \tVal Acc: 0.3143939393939394\n","Epoch: 10 \tLoss: 1865.4017344996682 \tTraining Acc: 0.4251893939393939 \tVal Acc: 0.3787878787878788\n","Epoch: 11 \tLoss: 1683.504168131738 \tTraining Acc: 0.4943181818181818 \tVal Acc: 0.3939393939393939\n","Epoch: 12 \tLoss: 1620.7468348528491 \tTraining Acc: 0.5047348484848485 \tVal Acc: 0.3977272727272727\n","Epoch: 13 \tLoss: 1459.5485166148974 \tTraining Acc: 0.5482954545454546 \tVal Acc: 0.4166666666666667\n","Epoch: 14 \tLoss: 1277.721444843607 \tTraining Acc: 0.6136363636363636 \tVal Acc: 0.3560606060606061\n","Epoch: 15 \tLoss: 1127.472487490384 \tTraining Acc: 0.6524621212121212 \tVal Acc: 0.45075757575757575\n","Epoch: 16 \tLoss: 1072.5480248472522 \tTraining Acc: 0.6553030303030303 \tVal Acc: 0.48484848484848486\n","Epoch: 17 \tLoss: 980.6919525736521 \tTraining Acc: 0.696969696969697 \tVal Acc: 0.4621212121212121\n","Epoch: 18 \tLoss: 875.4076542500188 \tTraining Acc: 0.7367424242424242 \tVal Acc: 0.5113636363636364\n","Epoch: 19 \tLoss: 761.349040832712 \tTraining Acc: 0.7689393939393939 \tVal Acc: 0.553030303030303\n","Epoch: 20 \tLoss: 719.9298782024468 \tTraining Acc: 0.7670454545454546 \tVal Acc: 0.4734848484848485\n","Epoch: 21 \tLoss: 628.9594370288526 \tTraining Acc: 0.8153409090909091 \tVal Acc: 0.48484848484848486\n","Epoch: 22 \tLoss: 565.63355404699 \tTraining Acc: 0.8229166666666666 \tVal Acc: 0.5151515151515151\n","Epoch: 23 \tLoss: 482.1412212023616 \tTraining Acc: 0.8551136363636364 \tVal Acc: 0.5378787878787878\n","Epoch: 24 \tLoss: 456.59441514623654 \tTraining Acc: 0.8607954545454546 \tVal Acc: 0.5946969696969697\n","Epoch: 25 \tLoss: 424.6992328128117 \tTraining Acc: 0.8674242424242424 \tVal Acc: 0.4962121212121212\n","Epoch: 26 \tLoss: 409.11123079635934 \tTraining Acc: 0.8910984848484849 \tVal Acc: 0.5681818181818182\n","Epoch: 27 \tLoss: 336.6949441268644 \tTraining Acc: 0.9053030303030303 \tVal Acc: 0.5833333333333334\n","Epoch: 28 \tLoss: 312.2307780463056 \tTraining Acc: 0.90625 \tVal Acc: 0.5757575757575758\n","Epoch: 29 \tLoss: 272.262066967672 \tTraining Acc: 0.9185606060606061 \tVal Acc: 0.5681818181818182\n","\n","Test Acc: 0.576\n","```\n","\n","10 classes:\n","```\n","Epoch: 0 \tLoss: 1569.385221838951 \tTraining Acc: 0.10471976401179942 \tVal Acc: 0.1\n","Epoch: 1 \tLoss: 1546.6396800279617 \tTraining Acc: 0.12684365781710916 \tVal Acc: 0.23529411764705882\n","Epoch: 2 \tLoss: 1475.479916214943 \tTraining Acc: 0.20353982300884957 \tVal Acc: 0.27058823529411763\n","Epoch: 3 \tLoss: 1392.827352464199 \tTraining Acc: 0.26548672566371684 \tVal Acc: 0.4117647058823529\n","Epoch: 4 \tLoss: 1276.589142397046 \tTraining Acc: 0.3023598820058997 \tVal Acc: 0.3352941176470588\n","Epoch: 5 \tLoss: 1189.5225101336837 \tTraining Acc: 0.33185840707964603 \tVal Acc: 0.37058823529411766\n","Epoch: 6 \tLoss: 1088.0845762304962 \tTraining Acc: 0.37315634218289084 \tVal Acc: 0.5470588235294118\n","Epoch: 7 \tLoss: 1007.4069103263319 \tTraining Acc: 0.43805309734513276 \tVal Acc: 0.4823529411764706\n","Epoch: 8 \tLoss: 923.5357307894155 \tTraining Acc: 0.4823008849557522 \tVal Acc: 0.4176470588235294\n","Epoch: 9 \tLoss: 871.1508226243313 \tTraining Acc: 0.5191740412979351 \tVal Acc: 0.5\n","Epoch: 10 \tLoss: 780.5880819541926 \tTraining Acc: 0.5589970501474927 \tVal Acc: 0.5941176470588235\n","Epoch: 11 \tLoss: 674.5640695267357 \tTraining Acc: 0.6342182890855457 \tVal Acc: 0.6235294117647059\n","Epoch: 12 \tLoss: 623.4179306103451 \tTraining Acc: 0.6489675516224189 \tVal Acc: 0.6764705882352942\n","Epoch: 13 \tLoss: 540.8592538857229 \tTraining Acc: 0.7153392330383481 \tVal Acc: 0.6705882352941176\n","Epoch: 14 \tLoss: 492.0809788762722 \tTraining Acc: 0.7197640117994101 \tVal Acc: 0.7411764705882353\n","Epoch: 15 \tLoss: 423.32670283127663 \tTraining Acc: 0.7817109144542773 \tVal Acc: 0.7705882352941177\n","Epoch: 16 \tLoss: 369.16708188707287 \tTraining Acc: 0.799410029498525 \tVal Acc: 0.7235294117647059\n","Epoch: 17 \tLoss: 330.93447673034143 \tTraining Acc: 0.8259587020648967 \tVal Acc: 0.8117647058823529\n","Epoch: 18 \tLoss: 278.6914137442982 \tTraining Acc: 0.8628318584070797 \tVal Acc: 0.788235294117647\n","Epoch: 19 \tLoss: 245.25940789678089 \tTraining Acc: 0.8864306784660767 \tVal Acc: 0.7588235294117647\n","Epoch: 20 \tLoss: 206.44183245867924 \tTraining Acc: 0.8893805309734514 \tVal Acc: 0.7588235294117647\n","Epoch: 21 \tLoss: 157.95215109574428 \tTraining Acc: 0.9277286135693216 \tVal Acc: 0.7941176470588235\n","Epoch: 22 \tLoss: 162.45883635203458 \tTraining Acc: 0.9188790560471977 \tVal Acc: 0.7705882352941177\n","Epoch: 23 \tLoss: 137.22218565423373 \tTraining Acc: 0.9410029498525073 \tVal Acc: 0.7647058823529411\n","Epoch: 24 \tLoss: 124.89940527370291 \tTraining Acc: 0.9528023598820059 \tVal Acc: 0.8352941176470589\n","Epoch: 25 \tLoss: 100.983948795479 \tTraining Acc: 0.9616519174041298 \tVal Acc: 0.8411764705882353\n","Epoch: 26 \tLoss: 100.87275485344367 \tTraining Acc: 0.948377581120944 \tVal Acc: 0.8294117647058824\n","Epoch: 27 \tLoss: 82.11014462643362 \tTraining Acc: 0.9705014749262537 \tVal Acc: 0.8411764705882353\n","Epoch: 28 \tLoss: 77.73273769133536 \tTraining Acc: 0.9705014749262537 \tVal Acc: 0.8352941176470589\n","Epoch: 29 \tLoss: 55.889662469958424 \tTraining Acc: 0.9823008849557522 \tVal Acc: 0.8588235294117647\n","\n","Test: 0.802\n","```\n","\n","<hr>\n","\n","Added equal split per class\n","```\n","Epoch: 0 \tLoss: 1528.9663017988205 \tTraining Acc: 0.09242424242424242 \tVal Acc: 0.11666666666666667\n","Epoch: 1 \tLoss: 1502.679721236229 \tTraining Acc: 0.15757575757575756 \tVal Acc: 0.2111111111111111\n","Epoch: 2 \tLoss: 1463.5338008403778 \tTraining Acc: 0.1621212121212121 \tVal Acc: 0.26666666666666666\n","Epoch: 3 \tLoss: 1372.7203063964844 \tTraining Acc: 0.25303030303030305 \tVal Acc: 0.37777777777777777\n","Epoch: 4 \tLoss: 1244.0758409798145 \tTraining Acc: 0.32727272727272727 \tVal Acc: 0.4222222222222222\n","Epoch: 5 \tLoss: 1121.3936377167702 \tTraining Acc: 0.36363636363636365 \tVal Acc: 0.4222222222222222\n","Epoch: 6 \tLoss: 1009.2355154734105 \tTraining Acc: 0.4303030303030303 \tVal Acc: 0.5\n","Epoch: 7 \tLoss: 912.3891499266028 \tTraining Acc: 0.4666666666666667 \tVal Acc: 0.5666666666666667\n","Epoch: 8 \tLoss: 802.6440292969346 \tTraining Acc: 0.5545454545454546 \tVal Acc: 0.6444444444444445\n","Epoch: 9 \tLoss: 735.3432892244309 \tTraining Acc: 0.5696969696969697 \tVal Acc: 0.65\n","Epoch: 10 \tLoss: 666.9478785937536 \tTraining Acc: 0.6212121212121212 \tVal Acc: 0.6611111111111111\n","Epoch: 11 \tLoss: 591.0443014791235 \tTraining Acc: 0.6818181818181818 \tVal Acc: 0.6388888888888888\n","Epoch: 12 \tLoss: 496.5321105477051 \tTraining Acc: 0.7257575757575757 \tVal Acc: 0.6722222222222223\n","Epoch: 13 \tLoss: 446.6869826923589 \tTraining Acc: 0.7560606060606061 \tVal Acc: 0.7111111111111111\n","Epoch: 14 \tLoss: 367.4004441020443 \tTraining Acc: 0.8272727272727273 \tVal Acc: 0.7611111111111111\n","Epoch: 15 \tLoss: 322.6218070056166 \tTraining Acc: 0.8318181818181818 \tVal Acc: 0.7722222222222223\n","Epoch: 16 \tLoss: 297.68052879207244 \tTraining Acc: 0.853030303030303 \tVal Acc: 0.6388888888888888\n","Epoch: 17 \tLoss: 240.15884953091881 \tTraining Acc: 0.8636363636363636 \tVal Acc: 0.7777777777777778\n","Epoch: 18 \tLoss: 223.34118653787618 \tTraining Acc: 0.8833333333333333 \tVal Acc: 0.8222222222222222\n","Epoch: 19 \tLoss: 195.8165926825177 \tTraining Acc: 0.9015151515151515 \tVal Acc: 0.75\n","Epoch: 20 \tLoss: 174.60090274833294 \tTraining Acc: 0.9196969696969697 \tVal Acc: 0.7944444444444444\n","Epoch: 21 \tLoss: 139.5507349503913 \tTraining Acc: 0.9348484848484848 \tVal Acc: 0.8555555555555555\n","Epoch: 22 \tLoss: 146.09908531672738 \tTraining Acc: 0.9272727272727272 \tVal Acc: 0.8111111111111111\n","Epoch: 23 \tLoss: 109.12153381752239 \tTraining Acc: 0.9484848484848485 \tVal Acc: 0.8111111111111111\n","Epoch: 24 \tLoss: 99.60142870776207 \tTraining Acc: 0.956060606060606 \tVal Acc: 0.85\n","Epoch: 25 \tLoss: 93.80636242912291 \tTraining Acc: 0.9590909090909091 \tVal Acc: 0.8555555555555555\n","Epoch: 26 \tLoss: 74.04265433399226 \tTraining Acc: 0.9696969696969697 \tVal Acc: 0.8777777777777778\n","Epoch: 27 \tLoss: 91.88863193862318 \tTraining Acc: 0.9575757575757575 \tVal Acc: 0.8333333333333334\n","Epoch: 28 \tLoss: 60.1019510711011 \tTraining Acc: 0.9681818181818181 \tVal Acc: 0.8444444444444444\n","Epoch: 29 \tLoss: 62.56993119053227 \tTraining Acc: 0.9681818181818181 \tVal Acc: 0.8555555555555555\n","\n","Test: 0.745\n","```"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"vscode":{"interpreter":{"hash":"8ffc022e556dbf9e4707e0813792d41f1f0550f46106b79e6c9a363a1f17dd45"}}},"nbformat":4,"nbformat_minor":4}
