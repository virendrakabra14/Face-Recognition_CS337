{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"8ffc022e556dbf9e4707e0813792d41f1f0550f46106b79e6c9a363a1f17dd45"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\n\ntry:\n    from torchinfo import summary\nexcept ModuleNotFoundError:\n    !pip install torchinfo\n    from torchinfo import summary\n\nimport os\nimport pathlib\nimport shutil\nimport sys","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:26.850428Z","iopub.execute_input":"2022-11-22T16:34:26.851066Z","iopub.status.idle":"2022-11-22T16:34:42.382296Z","shell.execute_reply.started":"2022-11-22T16:34:26.850928Z","shell.execute_reply":"2022-11-22T16:34:42.380932Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchinfo\n  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\nInstalling collected packages: torchinfo\nSuccessfully installed torchinfo-1.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nSame dir structure as on Kaggle\ninput/\n    lfw-dataset/\n        csv files\n        lfw-deepfunneled/\nworking/\n    notebook\n    data/\n        train/\n        val/\n        test/\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.384880Z","iopub.execute_input":"2022-11-22T16:34:42.386148Z","iopub.status.idle":"2022-11-22T16:34:42.395812Z","shell.execute_reply.started":"2022-11-22T16:34:42.386104Z","shell.execute_reply":"2022-11-22T16:34:42.394601Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'\\nSame dir structure as on Kaggle\\ninput/\\n    lfw-dataset/\\n        csv files\\n        lfw-deepfunneled/\\nworking/\\n    notebook\\n    data/\\n        train/\\n        val/\\n        test/\\n'"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(device)\n\n# https://towardsdatascience.com/pytorch-switching-to-the-gpu-a7c0b21e8a99\n# for modifications to use GPU\n\n# Also this: https://github.com/pytorch/examples/blob/main/imagenet/main.py","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.397233Z","iopub.execute_input":"2022-11-22T16:34:42.398271Z","iopub.status.idle":"2022-11-22T16:34:42.517892Z","shell.execute_reply.started":"2022-11-22T16:34:42.398224Z","shell.execute_reply":"2022-11-22T16:34:42.516921Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"data_folder = '../input/lfw-dataset/'","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.521352Z","iopub.execute_input":"2022-11-22T16:34:42.521896Z","iopub.status.idle":"2022-11-22T16:34:42.527955Z","shell.execute_reply.started":"2022-11-22T16:34:42.521865Z","shell.execute_reply":"2022-11-22T16:34:42.526660Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"lfw_allnames = pd.read_csv(data_folder+\"lfw_allnames.csv\")\n\nimage_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\nimage_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\nimage_paths['image_path'] = image_paths.image_path.apply(lambda x: str(x).zfill(4))\nimage_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\nimage_paths = image_paths.drop(\"images\", axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.529445Z","iopub.execute_input":"2022-11-22T16:34:42.530036Z","iopub.status.idle":"2022-11-22T16:34:42.593866Z","shell.execute_reply.started":"2022-11-22T16:34:42.530001Z","shell.execute_reply":"2022-11-22T16:34:42.592993Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"num_ppl = 25\n\nprint(image_paths['name'].value_counts()[:num_ppl])\nlist_people = list(image_paths['name'].value_counts()[:num_ppl].keys())\nlist_num_images = list(image_paths['name'].value_counts()[:num_ppl])\nprint(list_people, list_num_images)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.594973Z","iopub.execute_input":"2022-11-22T16:34:42.595312Z","iopub.status.idle":"2022-11-22T16:34:42.616809Z","shell.execute_reply.started":"2022-11-22T16:34:42.595277Z","shell.execute_reply":"2022-11-22T16:34:42.615705Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"George_W_Bush                530\nColin_Powell                 236\nTony_Blair                   144\nDonald_Rumsfeld              121\nGerhard_Schroeder            109\nAriel_Sharon                  77\nHugo_Chavez                   71\nJunichiro_Koizumi             60\nJean_Chretien                 55\nJohn_Ashcroft                 53\nJacques_Chirac                52\nSerena_Williams               52\nVladimir_Putin                49\nLuiz_Inacio_Lula_da_Silva     48\nGloria_Macapagal_Arroyo       44\nJennifer_Capriati             42\nArnold_Schwarzenegger         42\nLaura_Bush                    41\nLleyton_Hewitt                41\nHans_Blix                     39\nAlejandro_Toledo              39\nNestor_Kirchner               37\nAndre_Agassi                  36\nAlvaro_Uribe                  35\nSilvio_Berlusconi             33\nName: name, dtype: int64\n['George_W_Bush', 'Colin_Powell', 'Tony_Blair', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Ariel_Sharon', 'Hugo_Chavez', 'Junichiro_Koizumi', 'Jean_Chretien', 'John_Ashcroft', 'Jacques_Chirac', 'Serena_Williams', 'Vladimir_Putin', 'Luiz_Inacio_Lula_da_Silva', 'Gloria_Macapagal_Arroyo', 'Jennifer_Capriati', 'Arnold_Schwarzenegger', 'Laura_Bush', 'Lleyton_Hewitt', 'Hans_Blix', 'Alejandro_Toledo', 'Nestor_Kirchner', 'Andre_Agassi', 'Alvaro_Uribe', 'Silvio_Berlusconi'] [530, 236, 144, 121, 109, 77, 71, 60, 55, 53, 52, 52, 49, 48, 44, 42, 42, 41, 41, 39, 39, 37, 36, 35, 33]\n","output_type":"stream"}]},{"cell_type":"code","source":"num_for_each = image_paths['name'].value_counts()[num_ppl-1]\ntmp_l = []\nfor name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\n    tmp_l.append(image_paths[image_paths.name==name].sample(num_for_each))\ndata = pd.concat(tmp_l)\nprint(data)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.618043Z","iopub.execute_input":"2022-11-22T16:34:42.618353Z","iopub.status.idle":"2022-11-22T16:34:42.671762Z","shell.execute_reply.started":"2022-11-22T16:34:42.618318Z","shell.execute_reply":"2022-11-22T16:34:42.670716Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"                   name                                    image_path\n1871      George_W_Bush          George_W_Bush/George_W_Bush_0297.jpg\n1871      George_W_Bush          George_W_Bush/George_W_Bush_0227.jpg\n1871      George_W_Bush          George_W_Bush/George_W_Bush_0186.jpg\n1871      George_W_Bush          George_W_Bush/George_W_Bush_0336.jpg\n1871      George_W_Bush          George_W_Bush/George_W_Bush_0045.jpg\n...                 ...                                           ...\n5039  Silvio_Berlusconi  Silvio_Berlusconi/Silvio_Berlusconi_0016.jpg\n5039  Silvio_Berlusconi  Silvio_Berlusconi/Silvio_Berlusconi_0022.jpg\n5039  Silvio_Berlusconi  Silvio_Berlusconi/Silvio_Berlusconi_0001.jpg\n5039  Silvio_Berlusconi  Silvio_Berlusconi/Silvio_Berlusconi_0024.jpg\n5039  Silvio_Berlusconi  Silvio_Berlusconi/Silvio_Berlusconi_0021.jpg\n\n[825 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"data_train, data_test = train_test_split(data, test_size=0.2)\ndata_train, data_val = train_test_split(data_train, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.673252Z","iopub.execute_input":"2022-11-22T16:34:42.673714Z","iopub.status.idle":"2022-11-22T16:34:42.681830Z","shell.execute_reply.started":"2022-11-22T16:34:42.673669Z","shell.execute_reply":"2022-11-22T16:34:42.680756Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(data_train.shape, data_val.shape, data_test.shape)        # before augmentation","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.683220Z","iopub.execute_input":"2022-11-22T16:34:42.683728Z","iopub.status.idle":"2022-11-22T16:34:42.694900Z","shell.execute_reply.started":"2022-11-22T16:34:42.683691Z","shell.execute_reply":"2022-11-22T16:34:42.693789Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(528, 2) (132, 2) (165, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_root = './data/'\n\ndata_list = [data_train, data_val, data_test]\ndirs = ['train', 'val', 'test']\n\n# \"\"\"             # (un)comment this line (only) and run, to copy\n\n# # remove data directory if it exists\nif os.path.exists(data_root) and os.path.isdir(data_root):\n    shutil.rmtree(data_root)\n\ntransform_augment = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=1)\n])\n\nfor i in range(len(dirs)):\n    pathlib.Path(os.path.join(data_root, dirs[i])).mkdir(parents=True, exist_ok=True)\n    \n    for person in list_people:\n        if len(data_train[data_train['name']==person])>0:\n            pathlib.Path(os.path.join(data_root, dirs[i], person)).mkdir(parents=True, exist_ok=True)\n\n    for im_path in data_list[i].image_path:\n        name = data[data['image_path']==im_path]['name'].iloc[0]\n        path_from = os.path.join(data_folder+'/lfw-deepfunneled/lfw-deepfunneled/', im_path)\n        filename, file_extension = os.path.splitext(path_from.split('/')[-1])\n        path_to = os.path.join(data_root, dirs[i], name)\n\n        if not os.path.isfile(os.path.join(path_to, im_path)):\n            shutil.copy(path_from, path_to)         # earlier (just copies image)\n            \n            # if dirs[i]!='test':                   # test-time augmentation too?\n            img = Image.open(path_from)\n            img = transform_augment(img)            # transformed image\n            img.save(path_to+'/'+filename+'_transformed'+file_extension)\n\n# \"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:42.700706Z","iopub.execute_input":"2022-11-22T16:34:42.701003Z","iopub.status.idle":"2022-11-22T16:34:52.243334Z","shell.execute_reply.started":"2022-11-22T16:34:42.700978Z","shell.execute_reply":"2022-11-22T16:34:52.242317Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_path = os.path.join(data_root, dirs[0])\nval_path = os.path.join(data_root, dirs[1])\ntest_path = os.path.join(data_root, dirs[2])\n\ntrain_transform = transforms.Compose(transforms=[\n    # transforms.RandomHorizontalFlip(),\n    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n    transforms.ToTensor(),\n    # transforms.Normalize(mean=0, std=255),      # output = (input-mean)/std\n])\ntest_transform = transforms.Compose(transforms=[\n    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n    transforms.ToTensor(),\n    # transforms.Normalize(mean=0, std=255)\n])\n\ndataloader_kwargs = {\n    'pin_memory': True,\n    'num_workers': 1,\n    'batch_size': 1,\n    'shuffle': True\n}\nnon_blocking = dataloader_kwargs['pin_memory']  # https://stackoverflow.com/questions/55563376/\n\ntrain_loader = DataLoader(\n    torchvision.datasets.ImageFolder(train_path, train_transform), **dataloader_kwargs\n)\nval_loader = DataLoader(\n    torchvision.datasets.ImageFolder(val_path, test_transform), **dataloader_kwargs\n)\ntest_loader = DataLoader(\n    torchvision.datasets.ImageFolder(test_path, test_transform), **dataloader_kwargs\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:52.244685Z","iopub.execute_input":"2022-11-22T16:34:52.245086Z","iopub.status.idle":"2022-11-22T16:34:52.265388Z","shell.execute_reply.started":"2022-11-22T16:34:52.245049Z","shell.execute_reply":"2022-11-22T16:34:52.264521Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for data in train_loader:\n    print(data[0].shape, data[1].shape)\n    # print(data[0], data[1])\n    print(torch.mean(data[0]))\n    break\n# Total train data is of shape (128, 3, 250, 250)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:52.266804Z","iopub.execute_input":"2022-11-22T16:34:52.267362Z","iopub.status.idle":"2022-11-22T16:34:55.586197Z","shell.execute_reply.started":"2022-11-22T16:34:52.267325Z","shell.execute_reply":"2022-11-22T16:34:55.585080Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 250, 250]) torch.Size([1])\ntensor(0.3906)\n","output_type":"stream"}]},{"cell_type":"code","source":"class FaceCNN_initial(nn.Module):\n    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n        super().__init__()\n\n        self.network = nn.Sequential(\n\n        nn.Conv2d(in_channels=num_input_channels, out_channels=50, kernel_size=3, stride=stride, padding=padding),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2),\n\n        nn.Conv2d(in_channels=50, out_channels=20, kernel_size=3, stride=stride, padding=padding),\n        nn.ReLU(),\n\n        nn.Flatten(),\n        nn.Linear(in_features=20*125*125, out_features=num_classes)\n\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:55.587934Z","iopub.execute_input":"2022-11-22T16:34:55.588622Z","iopub.status.idle":"2022-11-22T16:34:55.597536Z","shell.execute_reply.started":"2022-11-22T16:34:55.588574Z","shell.execute_reply":"2022-11-22T16:34:55.596415Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class FaceCNN(nn.Module):\n    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n        super().__init__()\n\n        self.network = nn.Sequential(\n\n            # (250, 250, 3)\n\n            nn.Conv2d(in_channels=num_input_channels, out_channels=64, kernel_size=7, stride=2, padding=padding),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(p=0.2),\n\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=padding),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(p=0.2),\n\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=stride, padding=padding),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(p=0.2),\n\n            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=stride, padding=padding),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            # nn.MaxPool2d(kernel_size=2),\n            nn.Dropout(p=0.2),\n\n            nn.Flatten(),\n            nn.Linear(in_features=14400, out_features=1024),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),    # https://stats.stackexchange.com/questions/240305/\n            nn.Linear(in_features=1024, out_features=64),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(in_features=64, out_features=num_classes),\n\n        )\n\n    def forward(self, input):\n        output = self.network(input)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:34:55.599359Z","iopub.execute_input":"2022-11-22T16:34:55.599919Z","iopub.status.idle":"2022-11-22T16:34:55.613484Z","shell.execute_reply.started":"2022-11-22T16:34:55.599881Z","shell.execute_reply":"2022-11-22T16:34:55.611989Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"num_input_channels = 3\nmodel = FaceCNN(num_input_channels=num_input_channels, num_classes=len(list_people)).to(device)\n# for e in model.parameters():\n#     print(e)\nprint(summary(model, input_size=(dataloader_kwargs['batch_size'], num_input_channels, 250, 250)))\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)\nloss_fn = nn.CrossEntropyLoss()\nnum_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:37:10.312413Z","iopub.execute_input":"2022-11-22T16:37:10.312843Z","iopub.status.idle":"2022-11-22T16:37:10.499996Z","shell.execute_reply.started":"2022-11-22T16:37:10.312801Z","shell.execute_reply":"2022-11-22T16:37:10.498900Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nFaceCNN                                  [1, 25]                   --\n├─Sequential: 1-1                        [1, 25]                   --\n│    └─Conv2d: 2-1                       [1, 64, 123, 123]         9,472\n│    └─BatchNorm2d: 2-2                  [1, 64, 123, 123]         128\n│    └─ReLU: 2-3                         [1, 64, 123, 123]         --\n│    └─MaxPool2d: 2-4                    [1, 64, 61, 61]           --\n│    └─Dropout: 2-5                      [1, 64, 61, 61]           --\n│    └─Conv2d: 2-6                       [1, 128, 61, 61]          73,856\n│    └─BatchNorm2d: 2-7                  [1, 128, 61, 61]          256\n│    └─ReLU: 2-8                         [1, 128, 61, 61]          --\n│    └─MaxPool2d: 2-9                    [1, 128, 30, 30]          --\n│    └─Dropout: 2-10                     [1, 128, 30, 30]          --\n│    └─Conv2d: 2-11                      [1, 256, 30, 30]          295,168\n│    └─BatchNorm2d: 2-12                 [1, 256, 30, 30]          512\n│    └─ReLU: 2-13                        [1, 256, 30, 30]          --\n│    └─MaxPool2d: 2-14                   [1, 256, 15, 15]          --\n│    └─Dropout: 2-15                     [1, 256, 15, 15]          --\n│    └─Conv2d: 2-16                      [1, 64, 15, 15]           147,520\n│    └─BatchNorm2d: 2-17                 [1, 64, 15, 15]           128\n│    └─ReLU: 2-18                        [1, 64, 15, 15]           --\n│    └─Dropout: 2-19                     [1, 64, 15, 15]           --\n│    └─Flatten: 2-20                     [1, 14400]                --\n│    └─Linear: 2-21                      [1, 1024]                 14,746,624\n│    └─ReLU: 2-22                        [1, 1024]                 --\n│    └─Dropout: 2-23                     [1, 1024]                 --\n│    └─Linear: 2-24                      [1, 64]                   65,600\n│    └─ReLU: 2-25                        [1, 64]                   --\n│    └─Dropout: 2-26                     [1, 64]                   --\n│    └─Linear: 2-27                      [1, 25]                   1,625\n==========================================================================================\nTotal params: 15,340,889\nTrainable params: 15,340,889\nNon-trainable params: 0\nTotal mult-adds (M): 731.78\n==========================================================================================\nInput size (MB): 0.75\nForward/backward pass size (MB): 27.04\nParams size (MB): 61.36\nEstimated Total Size (MB): 89.15\n==========================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(loader, model):\n\n    model.eval()\n\n    score = 0\n    cnt = 0\n\n    with torch.no_grad():       # not training, so no need to calculate gradients\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n            output = model(inputs)\n            _, pred = torch.max(output.data, 1)\n            score += float(torch.sum(pred==labels.data))\n            cnt += data[0].shape[0]\n\n    return score/cnt","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:37:11.031323Z","iopub.execute_input":"2022-11-22T16:37:11.031680Z","iopub.status.idle":"2022-11-22T16:37:11.039172Z","shell.execute_reply.started":"2022-11-22T16:37:11.031650Z","shell.execute_reply":"2022-11-22T16:37:11.037909Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train():\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        train_score = 0\n        cnt = 0\n        train_loss = 0\n\n        model.train()\n        \n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n\n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            \n            # print(outputs, labels)\n\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n\n            _, preds = torch.max(outputs.data, 1)\n            train_score += float(torch.sum(preds==labels.data))\n            cnt += inputs.shape[0]\n\n            # print(preds, labels)\n\n        train_acc = train_score/cnt\n        val_acc = evaluate(val_loader, model)\n        \n        print(\"Epoch:\", epoch, \"\\tLoss:\", train_loss, \"\\tTraining Acc:\", train_acc, \"\\tVal Acc:\", val_acc)\n\n        if val_acc > best_acc:\n            torch.save(model.state_dict(),'best.model')\n            best_acc = val_acc","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:37:12.426304Z","iopub.execute_input":"2022-11-22T16:37:12.426661Z","iopub.status.idle":"2022-11-22T16:37:12.436369Z","shell.execute_reply.started":"2022-11-22T16:37:12.426628Z","shell.execute_reply":"2022-11-22T16:37:12.435300Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:37:12.871056Z","iopub.execute_input":"2022-11-22T16:37:12.871426Z","iopub.status.idle":"2022-11-22T16:42:59.722093Z","shell.execute_reply.started":"2022-11-22T16:37:12.871395Z","shell.execute_reply":"2022-11-22T16:42:59.719612Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch: 0 \tLoss: 3413.37361741066 \tTraining Acc: 0.041666666666666664 \tVal Acc: 0.022727272727272728\nEpoch: 1 \tLoss: 3346.7614665031433 \tTraining Acc: 0.07196969696969698 \tVal Acc: 0.05303030303030303\nEpoch: 2 \tLoss: 3201.3032276034355 \tTraining Acc: 0.09753787878787878 \tVal Acc: 0.10606060606060606\nEpoch: 3 \tLoss: 3079.741751715541 \tTraining Acc: 0.12973484848484848 \tVal Acc: 0.125\nEpoch: 4 \tLoss: 2865.667134359479 \tTraining Acc: 0.17518939393939395 \tVal Acc: 0.18181818181818182\nEpoch: 5 \tLoss: 2718.3486230820417 \tTraining Acc: 0.19412878787878787 \tVal Acc: 0.19696969696969696\nEpoch: 6 \tLoss: 2579.4593008980155 \tTraining Acc: 0.22443181818181818 \tVal Acc: 0.25\nEpoch: 7 \tLoss: 2391.6380325537175 \tTraining Acc: 0.29829545454545453 \tVal Acc: 0.30303030303030304\nEpoch: 8 \tLoss: 2201.1669663584325 \tTraining Acc: 0.3484848484848485 \tVal Acc: 0.23863636363636365\nEpoch: 9 \tLoss: 2032.1635219482705 \tTraining Acc: 0.38920454545454547 \tVal Acc: 0.3143939393939394\nEpoch: 10 \tLoss: 1865.4017344996682 \tTraining Acc: 0.4251893939393939 \tVal Acc: 0.3787878787878788\nEpoch: 11 \tLoss: 1683.504168131738 \tTraining Acc: 0.4943181818181818 \tVal Acc: 0.3939393939393939\nEpoch: 12 \tLoss: 1620.7468348528491 \tTraining Acc: 0.5047348484848485 \tVal Acc: 0.3977272727272727\nEpoch: 13 \tLoss: 1459.5485166148974 \tTraining Acc: 0.5482954545454546 \tVal Acc: 0.4166666666666667\nEpoch: 14 \tLoss: 1277.721444843607 \tTraining Acc: 0.6136363636363636 \tVal Acc: 0.3560606060606061\nEpoch: 15 \tLoss: 1127.472487490384 \tTraining Acc: 0.6524621212121212 \tVal Acc: 0.45075757575757575\nEpoch: 16 \tLoss: 1072.5480248472522 \tTraining Acc: 0.6553030303030303 \tVal Acc: 0.48484848484848486\nEpoch: 17 \tLoss: 980.6919525736521 \tTraining Acc: 0.696969696969697 \tVal Acc: 0.4621212121212121\nEpoch: 18 \tLoss: 875.4076542500188 \tTraining Acc: 0.7367424242424242 \tVal Acc: 0.5113636363636364\nEpoch: 19 \tLoss: 761.349040832712 \tTraining Acc: 0.7689393939393939 \tVal Acc: 0.553030303030303\nEpoch: 20 \tLoss: 719.9298782024468 \tTraining Acc: 0.7670454545454546 \tVal Acc: 0.4734848484848485\nEpoch: 21 \tLoss: 628.9594370288526 \tTraining Acc: 0.8153409090909091 \tVal Acc: 0.48484848484848486\nEpoch: 22 \tLoss: 565.63355404699 \tTraining Acc: 0.8229166666666666 \tVal Acc: 0.5151515151515151\nEpoch: 23 \tLoss: 482.1412212023616 \tTraining Acc: 0.8551136363636364 \tVal Acc: 0.5378787878787878\nEpoch: 24 \tLoss: 456.59441514623654 \tTraining Acc: 0.8607954545454546 \tVal Acc: 0.5946969696969697\nEpoch: 25 \tLoss: 424.6992328128117 \tTraining Acc: 0.8674242424242424 \tVal Acc: 0.4962121212121212\nEpoch: 26 \tLoss: 409.11123079635934 \tTraining Acc: 0.8910984848484849 \tVal Acc: 0.5681818181818182\nEpoch: 27 \tLoss: 336.6949441268644 \tTraining Acc: 0.9053030303030303 \tVal Acc: 0.5833333333333334\nEpoch: 28 \tLoss: 312.2307780463056 \tTraining Acc: 0.90625 \tVal Acc: 0.5757575757575758\nEpoch: 29 \tLoss: 272.262066967672 \tTraining Acc: 0.9185606060606061 \tVal Acc: 0.5681818181818182\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = torch.load('best.model')\nscore = 0\ncnt = 0\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n        output = model(inputs)\n        _, pred = torch.max(output.data, 1)\n        score += float(torch.sum(pred==labels.data))\n        cnt += data[0].shape[0]\n\nprint(score/cnt)","metadata":{"execution":{"iopub.status.busy":"2022-11-22T16:42:59.724515Z","iopub.execute_input":"2022-11-22T16:42:59.724975Z","iopub.status.idle":"2022-11-22T16:43:01.415289Z","shell.execute_reply.started":"2022-11-22T16:42:59.724929Z","shell.execute_reply":"2022-11-22T16:43:01.414213Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.5757575757575758\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train Stats\n\n```\nnum_ppl=4, num_for_each=100, num_input_channels=3, SGD\n\nEpoch: 0 \tLoss: 358.62260937690735 \tTraining Acc: 0.3046875 \tVal Acc: 0.390625\nEpoch: 1 \tLoss: 333.57504665851593 \tTraining Acc: 0.4453125 \tVal Acc: 0.5\nEpoch: 2 \tLoss: 287.8054849989712 \tTraining Acc: 0.53515625 \tVal Acc: 0.484375\nEpoch: 3 \tLoss: 214.57957464270294 \tTraining Acc: 0.66796875 \tVal Acc: 0.546875\nEpoch: 4 \tLoss: 128.76155146129895 \tTraining Acc: 0.8515625 \tVal Acc: 0.6875\nEpoch: 5 \tLoss: 66.8646472900873 \t    Training Acc: 0.9375 \t    Val Acc: 0.609375\nEpoch: 6 \tLoss: 38.552940751942515 \tTraining Acc: 0.96484375 \tVal Acc: 0.65625\nEpoch: 7 \tLoss: 14.400232573081496 \tTraining Acc: 0.99609375 \tVal Acc: 0.640625\nEpoch: 8 \tLoss: 6.6097561110264 \t    Training Acc: 1.0 \t        Val Acc: 0.71875\nEpoch: 9 \tLoss: 3.2570621859687208 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\nEpoch: 10 \tLoss: 2.2477716574980775 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\nEpoch: 11 \tLoss: 1.6625592309815147 \tTraining Acc: 1.0 \t        Val Acc: 0.734375\nEpoch: 12 \tLoss: 1.2643641760919024 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\nEpoch: 13 \tLoss: 1.0747595029670762 \tTraining Acc: 1.0 \t        Val Acc: 0.71875\nEpoch: 14 \tLoss: 0.8993665239690074 \tTraining Acc: 1.0 \t        Val Acc: 0.6875\n\nTest Acc: 0.85\n```\n<hr>\n\n```\nLarger network: num_ppl=25, num_for_each=33, num_input_channels=3, SGD, dropout=0.5, no dropout after conv layers\n\nEpoch: 0 \tLoss: 1701.3236393928528 \tTraining Acc: 0.05113636363636364 \tVal Acc: 0.08333333333333333\nEpoch: 1 \tLoss: 1648.1168529987335 \tTraining Acc: 0.08143939393939394 \tVal Acc: 0.13636363636363635\nEpoch: 2 \tLoss: 1570.683046221733 \tTraining Acc: 0.11742424242424243 \tVal Acc: 0.16666666666666666\nEpoch: 3 \tLoss: 1488.0452314019203 \tTraining Acc: 0.18181818181818182 \tVal Acc: 0.15151515151515152\nEpoch: 4 \tLoss: 1359.583057552576 \tTraining Acc: 0.22348484848484848 \tVal Acc: 0.17424242424242425\nEpoch: 5 \tLoss: 1259.4556982889771 \tTraining Acc: 0.3068181818181818 \tVal Acc: 0.25757575757575757\nEpoch: 6 \tLoss: 1127.6610003113747 \tTraining Acc: 0.3712121212121212 \tVal Acc: 0.2727272727272727\nEpoch: 7 \tLoss: 1039.084867735859 \tTraining Acc: 0.4090909090909091 \tVal Acc: 0.3333333333333333\nEpoch: 8 \tLoss: 917.1557948449627 \tTraining Acc: 0.4791666666666667 \tVal Acc: 0.2878787878787879\nEpoch: 9 \tLoss: 827.8774750904413 \tTraining Acc: 0.571969696969697 \tVal Acc: 0.45454545454545453\nEpoch: 10 \tLoss: 673.7398463344434 \tTraining Acc: 0.615530303030303 \tVal Acc: 0.38636363636363635\nEpoch: 11 \tLoss: 606.598319072742 \tTraining Acc: 0.678030303030303 \tVal Acc: 0.4318181818181818\nEpoch: 12 \tLoss: 502.92579286664113 \tTraining Acc: 0.7064393939393939 \tVal Acc: 0.44696969696969696\nEpoch: 13 \tLoss: 412.34249426988936 \tTraining Acc: 0.7765151515151515 \tVal Acc: 0.45454545454545453\nEpoch: 14 \tLoss: 329.6107653811632 \tTraining Acc: 0.8143939393939394 \tVal Acc: 0.5303030303030303\nEpoch: 15 \tLoss: 263.91059577577107 \tTraining Acc: 0.8731060606060606 \tVal Acc: 0.5303030303030303\nEpoch: 16 \tLoss: 248.08312809604558 \tTraining Acc: 0.8712121212121212 \tVal Acc: 0.4621212121212121\nEpoch: 17 \tLoss: 197.47446866694008 \tTraining Acc: 0.9090909090909091 \tVal Acc: 0.5227272727272727\nEpoch: 18 \tLoss: 172.28715605471052 \tTraining Acc: 0.9223484848484849 \tVal Acc: 0.5227272727272727\nEpoch: 19 \tLoss: 133.61397156973908 \tTraining Acc: 0.9375 \tVal Acc: 0.5681818181818182\n\nTest Acc: 0.59\n```\n<hr>\n\nLesser dropout, faster convergence (more fitting: 0.99 train acc, 0.58 val and test). Ofc not good always.\n\n<hr>\n\n```\nAdded dropout layers (p=0.2) after convolution: Train and val acc stay close for the first few (~10) epochs, but then diverge.\n    30 epochs. Test acc: 0.38.\n    50 epochs. Test acc: 0.55.\n\nEpoch: 0 \tLoss: 1706.7114553451538 \tTraining Acc: 0.05303030303030303 \tVal Acc: 0.06060606060606061\nEpoch: 1 \tLoss: 1703.110694885254 \tTraining Acc: 0.045454545454545456 \tVal Acc: 0.06818181818181818\nEpoch: 2 \tLoss: 1684.9260246753693 \tTraining Acc: 0.07196969696969698 \tVal Acc: 0.09090909090909091\nEpoch: 3 \tLoss: 1654.7403428554535 \tTraining Acc: 0.06818181818181818 \tVal Acc: 0.12121212121212122\nEpoch: 4 \tLoss: 1600.201600074768 \tTraining Acc: 0.11931818181818182 \tVal Acc: 0.1590909090909091\nEpoch: 5 \tLoss: 1548.975799292326 \tTraining Acc: 0.13636363636363635 \tVal Acc: 0.11363636363636363\nEpoch: 6 \tLoss: 1498.9787369072437 \tTraining Acc: 0.13446969696969696 \tVal Acc: 0.19696969696969696\nEpoch: 7 \tLoss: 1436.561501070857 \tTraining Acc: 0.20643939393939395 \tVal Acc: 0.22727272727272727\nEpoch: 8 \tLoss: 1384.87419853732 \tTraining Acc: 0.23863636363636365 \tVal Acc: 0.19696969696969696\nEpoch: 9 \tLoss: 1319.722053207457 \tTraining Acc: 0.26136363636363635 \tVal Acc: 0.23484848484848486\nEpoch: 10 \tLoss: 1251.95867273584 \tTraining Acc: 0.2859848484848485 \tVal Acc: 0.30303030303030304\nEpoch: 11 \tLoss: 1211.6356632895768 \tTraining Acc: 0.29734848484848486 \tVal Acc: 0.25757575757575757\nEpoch: 12 \tLoss: 1182.6897227037698 \tTraining Acc: 0.29734848484848486 \tVal Acc: 0.3181818181818182\nEpoch: 13 \tLoss: 1113.2747115662205 \tTraining Acc: 0.3484848484848485 \tVal Acc: 0.29545454545454547\nEpoch: 14 \tLoss: 1053.397371711675 \tTraining Acc: 0.3939393939393939 \tVal Acc: 0.3787878787878788\nEpoch: 15 \tLoss: 958.3644631365314 \tTraining Acc: 0.4431818181818182 \tVal Acc: 0.3484848484848485\nEpoch: 16 \tLoss: 938.4995879707858 \tTraining Acc: 0.4602272727272727 \tVal Acc: 0.36363636363636365\nEpoch: 17 \tLoss: 866.5983875243692 \tTraining Acc: 0.48863636363636365 \tVal Acc: 0.4015151515151515\nEpoch: 18 \tLoss: 822.6497887708247 \tTraining Acc: 0.5113636363636364 \tVal Acc: 0.3939393939393939\nEpoch: 19 \tLoss: 782.9832759417477 \tTraining Acc: 0.5435606060606061 \tVal Acc: 0.3939393939393939\nEpoch: 20 \tLoss: 698.3823288148269 \tTraining Acc: 0.5890151515151515 \tVal Acc: 0.3787878787878788\nEpoch: 21 \tLoss: 658.3069786201813 \tTraining Acc: 0.6231060606060606 \tVal Acc: 0.4090909090909091\nEpoch: 22 \tLoss: 569.9304089847283 \tTraining Acc: 0.634469696969697 \tVal Acc: 0.4393939393939394\nEpoch: 23 \tLoss: 622.2785371405917 \tTraining Acc: 0.6420454545454546 \tVal Acc: 0.4772727272727273\nEpoch: 24 \tLoss: 520.0580716890399 \tTraining Acc: 0.6761363636363636 \tVal Acc: 0.4696969696969697\nEpoch: 25 \tLoss: 448.39510909226374 \tTraining Acc: 0.75 \tVal Acc: 0.45454545454545453\nEpoch: 26 \tLoss: 429.5296724770451 \tTraining Acc: 0.759469696969697 \tVal Acc: 0.5\nEpoch: 27 \tLoss: 380.9049152136067 \tTraining Acc: 0.7746212121212122 \tVal Acc: 0.5\nEpoch: 28 \tLoss: 356.775621923327 \tTraining Acc: 0.8068181818181818 \tVal Acc: 0.5303030303030303\nEpoch: 29 \tLoss: 363.29747000594216 \tTraining Acc: 0.7859848484848485 \tVal Acc: 0.4772727272727273\nEpoch: 30 \tLoss: 297.8134929970547 \tTraining Acc: 0.8314393939393939 \tVal Acc: 0.5\nEpoch: 31 \tLoss: 282.2684114029398 \tTraining Acc: 0.8541666666666666 \tVal Acc: 0.4621212121212121\nEpoch: 32 \tLoss: 246.5776662196622 \tTraining Acc: 0.8522727272727273 \tVal Acc: 0.4696969696969697\nEpoch: 33 \tLoss: 242.04962211154543 \tTraining Acc: 0.8560606060606061 \tVal Acc: 0.5\nEpoch: 34 \tLoss: 208.3801038511872 \tTraining Acc: 0.8958333333333334 \tVal Acc: 0.5606060606060606\nEpoch: 35 \tLoss: 194.5455155442314 \tTraining Acc: 0.8996212121212122 \tVal Acc: 0.5227272727272727\nEpoch: 36 \tLoss: 158.61289137974723 \tTraining Acc: 0.9185606060606061 \tVal Acc: 0.5151515151515151\nEpoch: 37 \tLoss: 162.71159709136646 \tTraining Acc: 0.9034090909090909 \tVal Acc: 0.5\nEpoch: 38 \tLoss: 170.97251973819846 \tTraining Acc: 0.9015151515151515 \tVal Acc: 0.5075757575757576\nEpoch: 39 \tLoss: 157.24092914579478 \tTraining Acc: 0.9147727272727273 \tVal Acc: 0.553030303030303\nEpoch: 40 \tLoss: 133.82072701480678 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5\nEpoch: 41 \tLoss: 136.39509819635964 \tTraining Acc: 0.928030303030303 \tVal Acc: 0.553030303030303\nEpoch: 42 \tLoss: 126.88825436101558 \tTraining Acc: 0.9318181818181818 \tVal Acc: 0.5075757575757576\nEpoch: 43 \tLoss: 124.5683646489997 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5757575757575758\nEpoch: 44 \tLoss: 120.55329895571163 \tTraining Acc: 0.9337121212121212 \tVal Acc: 0.5\nEpoch: 45 \tLoss: 100.53747285808356 \tTraining Acc: 0.9356060606060606 \tVal Acc: 0.5378787878787878\nEpoch: 46 \tLoss: 92.43336634917796 \tTraining Acc: 0.9621212121212122 \tVal Acc: 0.5606060606060606\nEpoch: 47 \tLoss: 84.71885716843988 \tTraining Acc: 0.9564393939393939 \tVal Acc: 0.5303030303030303\nEpoch: 48 \tLoss: 80.6087966322365 \tTraining Acc: 0.9602272727272727 \tVal Acc: 0.5227272727272727\nEpoch: 49 \tLoss: 86.07536707191636 \tTraining Acc: 0.9564393939393939 \tVal Acc: 0.5378787878787878\n```\n\n<hr>\n\nBatch size 50: Train accuracy 4% even after 50 epochs. (25 ppl)\n\n<hr>\n\nData Augmentation. Horizontal flipping: 37% test acc after 10 epochs. (25 ppl)\n\n```\nEpoch: 0 \tLoss: 3413.37361741066 \tTraining Acc: 0.041666666666666664 \tVal Acc: 0.022727272727272728\nEpoch: 1 \tLoss: 3346.7614665031433 \tTraining Acc: 0.07196969696969698 \tVal Acc: 0.05303030303030303\nEpoch: 2 \tLoss: 3201.3032276034355 \tTraining Acc: 0.09753787878787878 \tVal Acc: 0.10606060606060606\nEpoch: 3 \tLoss: 3079.741751715541 \tTraining Acc: 0.12973484848484848 \tVal Acc: 0.125\nEpoch: 4 \tLoss: 2865.667134359479 \tTraining Acc: 0.17518939393939395 \tVal Acc: 0.18181818181818182\nEpoch: 5 \tLoss: 2718.3486230820417 \tTraining Acc: 0.19412878787878787 \tVal Acc: 0.19696969696969696\nEpoch: 6 \tLoss: 2579.4593008980155 \tTraining Acc: 0.22443181818181818 \tVal Acc: 0.25\nEpoch: 7 \tLoss: 2391.6380325537175 \tTraining Acc: 0.29829545454545453 \tVal Acc: 0.30303030303030304\nEpoch: 8 \tLoss: 2201.1669663584325 \tTraining Acc: 0.3484848484848485 \tVal Acc: 0.23863636363636365\nEpoch: 9 \tLoss: 2032.1635219482705 \tTraining Acc: 0.38920454545454547 \tVal Acc: 0.3143939393939394\nEpoch: 10 \tLoss: 1865.4017344996682 \tTraining Acc: 0.4251893939393939 \tVal Acc: 0.3787878787878788\nEpoch: 11 \tLoss: 1683.504168131738 \tTraining Acc: 0.4943181818181818 \tVal Acc: 0.3939393939393939\nEpoch: 12 \tLoss: 1620.7468348528491 \tTraining Acc: 0.5047348484848485 \tVal Acc: 0.3977272727272727\nEpoch: 13 \tLoss: 1459.5485166148974 \tTraining Acc: 0.5482954545454546 \tVal Acc: 0.4166666666666667\nEpoch: 14 \tLoss: 1277.721444843607 \tTraining Acc: 0.6136363636363636 \tVal Acc: 0.3560606060606061\nEpoch: 15 \tLoss: 1127.472487490384 \tTraining Acc: 0.6524621212121212 \tVal Acc: 0.45075757575757575\nEpoch: 16 \tLoss: 1072.5480248472522 \tTraining Acc: 0.6553030303030303 \tVal Acc: 0.48484848484848486\nEpoch: 17 \tLoss: 980.6919525736521 \tTraining Acc: 0.696969696969697 \tVal Acc: 0.4621212121212121\nEpoch: 18 \tLoss: 875.4076542500188 \tTraining Acc: 0.7367424242424242 \tVal Acc: 0.5113636363636364\nEpoch: 19 \tLoss: 761.349040832712 \tTraining Acc: 0.7689393939393939 \tVal Acc: 0.553030303030303\nEpoch: 20 \tLoss: 719.9298782024468 \tTraining Acc: 0.7670454545454546 \tVal Acc: 0.4734848484848485\nEpoch: 21 \tLoss: 628.9594370288526 \tTraining Acc: 0.8153409090909091 \tVal Acc: 0.48484848484848486\nEpoch: 22 \tLoss: 565.63355404699 \tTraining Acc: 0.8229166666666666 \tVal Acc: 0.5151515151515151\nEpoch: 23 \tLoss: 482.1412212023616 \tTraining Acc: 0.8551136363636364 \tVal Acc: 0.5378787878787878\nEpoch: 24 \tLoss: 456.59441514623654 \tTraining Acc: 0.8607954545454546 \tVal Acc: 0.5946969696969697\nEpoch: 25 \tLoss: 424.6992328128117 \tTraining Acc: 0.8674242424242424 \tVal Acc: 0.4962121212121212\nEpoch: 26 \tLoss: 409.11123079635934 \tTraining Acc: 0.8910984848484849 \tVal Acc: 0.5681818181818182\nEpoch: 27 \tLoss: 336.6949441268644 \tTraining Acc: 0.9053030303030303 \tVal Acc: 0.5833333333333334\nEpoch: 28 \tLoss: 312.2307780463056 \tTraining Acc: 0.90625 \tVal Acc: 0.5757575757575758\nEpoch: 29 \tLoss: 272.262066967672 \tTraining Acc: 0.9185606060606061 \tVal Acc: 0.5681818181818182\n\nTest Acc: 0.576\n```","metadata":{}}]}