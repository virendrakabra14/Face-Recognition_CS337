{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:42.899311Z","iopub.status.busy":"2022-11-23T23:47:42.898732Z","iopub.status.idle":"2022-11-23T23:47:55.781524Z","shell.execute_reply":"2022-11-23T23:47:55.780188Z","shell.execute_reply.started":"2022-11-23T23:47:42.899264Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.7.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["import cv2\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","\n","try:\n","    from torchinfo import summary\n","except ModuleNotFoundError:\n","    !pip install torchinfo\n","    from torchinfo import summary\n","\n","import os\n","import pathlib\n","import shutil\n","import sys"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:55.784754Z","iopub.status.busy":"2022-11-23T23:47:55.784301Z","iopub.status.idle":"2022-11-23T23:47:55.794266Z","shell.execute_reply":"2022-11-23T23:47:55.793180Z","shell.execute_reply.started":"2022-11-23T23:47:55.784705Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'\\nSame dir structure as on Kaggle\\ninput/\\n    lfw-dataset/\\n        csv files\\n        lfw-deepfunneled/\\nworking/\\n    notebook\\n    data/\\n        train/\\n        val/\\n        test/\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Same dir structure as on Kaggle\n","input/\n","    lfw-dataset/\n","        csv files\n","        lfw-deepfunneled/\n","working/\n","    notebook\n","    data/\n","        train/\n","        val/\n","        test/\n","\"\"\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:55.796471Z","iopub.status.busy":"2022-11-23T23:47:55.796028Z","iopub.status.idle":"2022-11-23T23:47:55.939037Z","shell.execute_reply":"2022-11-23T23:47:55.938164Z","shell.execute_reply.started":"2022-11-23T23:47:55.796433Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"data":{"text/plain":["<torch._C.Generator at 0x7faee6482090>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)\n","\n","# https://towardsdatascience.com/pytorch-switching-to-the-gpu-a7c0b21e8a99\n","# for modifications to use GPU\n","\n","# Also this: https://github.com/pytorch/examples/blob/main/imagenet/main.py\n","\n","np.random.seed(0)\n","torch.random.manual_seed(0)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:55.942154Z","iopub.status.busy":"2022-11-23T23:47:55.941762Z","iopub.status.idle":"2022-11-23T23:47:55.948401Z","shell.execute_reply":"2022-11-23T23:47:55.947428Z","shell.execute_reply.started":"2022-11-23T23:47:55.942100Z"},"trusted":true},"outputs":[],"source":["data_folder = '../input/lfw-dataset/'"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:55.951543Z","iopub.status.busy":"2022-11-23T23:47:55.951045Z","iopub.status.idle":"2022-11-23T23:47:56.028133Z","shell.execute_reply":"2022-11-23T23:47:56.027163Z","shell.execute_reply.started":"2022-11-23T23:47:55.951517Z"},"trusted":true},"outputs":[],"source":["lfw_allnames = pd.read_csv(data_folder+\"lfw_allnames.csv\")\n","\n","image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\n","image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\n","image_paths['image_path'] = image_paths.image_path.apply(lambda x: str(x).zfill(4))\n","image_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\n","image_paths = image_paths.drop(\"images\", axis=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:56.029705Z","iopub.status.busy":"2022-11-23T23:47:56.029361Z","iopub.status.idle":"2022-11-23T23:47:56.049686Z","shell.execute_reply":"2022-11-23T23:47:56.048791Z","shell.execute_reply.started":"2022-11-23T23:47:56.029666Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["George_W_Bush        530\n","Colin_Powell         236\n","Tony_Blair           144\n","Donald_Rumsfeld      121\n","Gerhard_Schroeder    109\n","Ariel_Sharon          77\n","Hugo_Chavez           71\n","Junichiro_Koizumi     60\n","Jean_Chretien         55\n","John_Ashcroft         53\n","Name: name, dtype: int64\n","['George_W_Bush', 'Colin_Powell', 'Tony_Blair', 'Donald_Rumsfeld', 'Gerhard_Schroeder', 'Ariel_Sharon', 'Hugo_Chavez', 'Junichiro_Koizumi', 'Jean_Chretien', 'John_Ashcroft'] [530, 236, 144, 121, 109, 77, 71, 60, 55, 53]\n"]}],"source":["num_ppl = 10\n","\n","print(image_paths['name'].value_counts()[:num_ppl])\n","list_people = list(image_paths['name'].value_counts()[:num_ppl].keys())\n","list_num_images = list(image_paths['name'].value_counts()[:num_ppl])\n","print(list_people, list_num_images)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:56.051600Z","iopub.status.busy":"2022-11-23T23:47:56.051233Z","iopub.status.idle":"2022-11-23T23:47:56.057996Z","shell.execute_reply":"2022-11-23T23:47:56.056753Z","shell.execute_reply.started":"2022-11-23T23:47:56.051548Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"\\nnum_for_each = image_paths['name'].value_counts()[num_ppl-1]\\ntmp_l = []\\nfor name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\\n    tmp_l.append(image_paths[image_paths.name==name].sample(num_for_each))\\ndata = pd.concat(tmp_l)\\nprint(data)\\n\""]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","num_for_each = image_paths['name'].value_counts()[num_ppl-1]\n","tmp_l = []\n","for name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\n","    tmp_l.append(image_paths[image_paths.name==name].sample(num_for_each))\n","data = pd.concat(tmp_l)\n","print(data)\n","\"\"\""]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:56.060269Z","iopub.status.busy":"2022-11-23T23:47:56.059897Z","iopub.status.idle":"2022-11-23T23:47:56.100820Z","shell.execute_reply":"2022-11-23T23:47:56.099833Z","shell.execute_reply.started":"2022-11-23T23:47:56.060236Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(330, 2) (90, 2) (110, 2)\n"]}],"source":["num_for_each = image_paths['name'].value_counts()[num_ppl-1]\n","tmp_train = []\n","tmp_val = []\n","tmp_test = []\n","for name in list(image_paths['name'].value_counts()[:num_ppl].keys()):\n","    data_all = image_paths[image_paths.name==name].sample(num_for_each)\n","    data_train, data_test = train_test_split(data_all, test_size=0.2)\n","    data_train, data_val = train_test_split(data_train, test_size=0.2)\n","    tmp_train.append(data_train.copy())\n","    tmp_val.append(data_val.copy())\n","    tmp_test.append(data_test.copy())\n","data_train = pd.concat(tmp_train)\n","data_val = pd.concat(tmp_val)\n","data_test = pd.concat(tmp_test)\n","print(data_train.shape, data_val.shape, data_test.shape)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-11-23T23:47:56.102586Z","iopub.status.busy":"2022-11-23T23:47:56.102247Z","iopub.status.idle":"2022-11-23T23:48:03.465045Z","shell.execute_reply":"2022-11-23T23:48:03.462855Z","shell.execute_reply.started":"2022-11-23T23:47:56.102553Z"},"trusted":true},"outputs":[],"source":["data_root = './data/'\n","\n","data_list = [data_train, data_val, data_test]\n","dirs = ['train', 'val', 'test']\n","\n","# \"\"\"             # (un)comment this line (only) and run, to copy\n","\n","# # remove data directory if it exists\n","if os.path.exists(data_root) and os.path.isdir(data_root):\n","    shutil.rmtree(data_root)\n","\n","transform_augment = transforms.Compose([\n","    transforms.RandomHorizontalFlip(p=1)\n","])\n","\n","for i in range(len(dirs)):\n","    pathlib.Path(os.path.join(data_root, dirs[i])).mkdir(parents=True, exist_ok=True)\n","    \n","    data = data_list[i]\n","\n","    for person in list_people:\n","        if len(data_train[data_train['name']==person])>0:\n","            pathlib.Path(os.path.join(data_root, dirs[i], person)).mkdir(parents=True, exist_ok=True)\n","\n","    for im_path in data_list[i].image_path:\n","        name = data[data['image_path']==im_path]['name'].iloc[0]\n","        path_from = os.path.join(data_folder+'/lfw-deepfunneled/lfw-deepfunneled/', im_path)\n","        filename, file_extension = os.path.splitext(path_from.split('/')[-1])\n","        path_to = os.path.join(data_root, dirs[i], name)\n","\n","        if not os.path.isfile(os.path.join(path_to, im_path)):\n","            shutil.copy(path_from, path_to)         # earlier (just copies image)\n","            \n","            # if dirs[i]!='test':                   # test-time augmentation too?\n","            img = Image.open(path_from)\n","            img = transform_augment(img)            # transformed image\n","            img.save(path_to+'/'+filename+'_transformed'+file_extension)\n","\n","# \"\"\""]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:16:48.658057Z","iopub.status.busy":"2022-11-24T00:16:48.657001Z","iopub.status.idle":"2022-11-24T00:16:48.677947Z","shell.execute_reply":"2022-11-24T00:16:48.676794Z","shell.execute_reply.started":"2022-11-24T00:16:48.658015Z"},"trusted":true},"outputs":[],"source":["train_path = os.path.join(data_root, dirs[0])\n","val_path = os.path.join(data_root, dirs[1])\n","test_path = os.path.join(data_root, dirs[2])\n","\n","train_transform = transforms.Compose(transforms=[\n","    # transforms.RandomHorizontalFlip(),\n","    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=0, std=255),      # output = (input-mean)/std\n","])\n","test_transform = transforms.Compose(transforms=[\n","    # transforms.Grayscale(num_output_channels=1),         # convert to grayscale\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=0, std=255)\n","])\n","\n","dataloader_kwargs = {\n","    'pin_memory': True,\n","    'num_workers': 1,\n","    'batch_size': 1,\n","    'shuffle': True\n","}\n","dataloader_kwargs_triplet = {\n","    'pin_memory': True,\n","    'num_workers': 1,\n","    'batch_size': 4,\n","    'shuffle': True\n","}\n","non_blocking = dataloader_kwargs['pin_memory']  # https://stackoverflow.com/questions/55563376/\n","\n","train_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(train_path, train_transform), **dataloader_kwargs\n",")\n","train_loader_triplet = DataLoader(\n","    torchvision.datasets.ImageFolder(train_path, train_transform), **dataloader_kwargs_triplet\n",")\n","val_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(val_path, test_transform), **dataloader_kwargs\n",")\n","test_loader = DataLoader(\n","    torchvision.datasets.ImageFolder(test_path, test_transform), **dataloader_kwargs\n",")"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:16:49.048226Z","iopub.status.busy":"2022-11-24T00:16:49.047846Z","iopub.status.idle":"2022-11-24T00:16:49.155632Z","shell.execute_reply":"2022-11-24T00:16:49.154429Z","shell.execute_reply.started":"2022-11-24T00:16:49.048194Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3, 250, 250]) torch.Size([1])\n","tensor(0.4668)\n"]}],"source":["for data in train_loader:\n","    print(data[0].shape, data[1].shape)\n","    # print(data[0], data[1])\n","    print(torch.mean(data[0]))\n","    break\n","# Total train data is of shape (128, 3, 250, 250)"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:16:49.309085Z","iopub.status.busy":"2022-11-24T00:16:49.308026Z","iopub.status.idle":"2022-11-24T00:16:49.317453Z","shell.execute_reply":"2022-11-24T00:16:49.316185Z","shell.execute_reply.started":"2022-11-24T00:16:49.309045Z"},"trusted":true},"outputs":[],"source":["class FaceCNN_initial(nn.Module):\n","    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n","        super().__init__()\n","\n","        self.network = nn.Sequential(\n","\n","        nn.Conv2d(in_channels=num_input_channels, out_channels=50, kernel_size=3, stride=stride, padding=padding),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2),\n","\n","        nn.Conv2d(in_channels=50, out_channels=20, kernel_size=3, stride=stride, padding=padding),\n","        nn.ReLU(),\n","\n","        nn.Flatten(),\n","        nn.Linear(in_features=20*125*125, out_features=num_classes)\n","\n","        )\n","\n","    def forward(self, input):\n","        output = self.network(input)\n","        return output"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:16:49.633095Z","iopub.status.busy":"2022-11-24T00:16:49.632662Z","iopub.status.idle":"2022-11-24T00:16:49.652650Z","shell.execute_reply":"2022-11-24T00:16:49.651478Z","shell.execute_reply.started":"2022-11-24T00:16:49.633057Z"},"trusted":true},"outputs":[],"source":["class FaceCNN(nn.Module):\n","    def __init__(self, num_input_channels, num_classes, stride=1, padding=1):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","\n","            # (250, 250, 3)\n","\n","            nn.Conv2d(in_channels=num_input_channels, out_channels=64, kernel_size=7, stride=2, padding=padding),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=padding),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=stride, padding=padding),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(in_channels=256, out_channels=64, kernel_size=3, stride=stride, padding=padding),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            # nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Flatten(),\n","            nn.Linear(in_features=14400, out_features=1024),\n","            nn.ReLU(),\n","            nn.Dropout(p=0.5),    # https://stats.stackexchange.com/questions/240305/\n","            nn.Linear(in_features=1024, out_features=64),\n","            nn.ReLU(),\n","        )\n","        self.decoder = nn.Sequential(        \n","            nn.Dropout(p=0.5),\n","            nn.Linear(in_features=64, out_features=num_classes),\n","        )\n","\n","    def forward(self, input):\n","        encoded = self.encoder(input)\n","        output = self.decoder(encoded)\n","        return output, encoded"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:33:15.208657Z","iopub.status.busy":"2022-11-24T00:33:15.208275Z","iopub.status.idle":"2022-11-24T00:33:15.218687Z","shell.execute_reply":"2022-11-24T00:33:15.217611Z","shell.execute_reply.started":"2022-11-24T00:33:15.208624Z"},"trusted":true},"outputs":[],"source":["def triplet_loss_fn(f, Y, num_classes, alpha=1, lam=0.01):\n","    # f is num_samples x output_dim_of_encoder (=64)\n","    # Y is categorical of size num_classes\n","    loss = 0\n","    for c in range(num_classes):\n","        p = f[Y==c]\n","        n = f[~(Y==c)]\n","        p_self = torch.sum((p[:,None,:]-p[None,:,:])**2, dim=2)\n","        p_n = torch.sum((p[:,None,:]-n[None,:,:])**2, dim=2)\n","        loss += torch.sum(torch.relu(p_self[:,:,None]-p_n[:,None,:]+alpha))\n","    return loss*lam"]},{"cell_type":"code","execution_count":108,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:38:14.221909Z","iopub.status.busy":"2022-11-24T00:38:14.221528Z","iopub.status.idle":"2022-11-24T00:38:14.403383Z","shell.execute_reply":"2022-11-24T00:38:14.402287Z","shell.execute_reply.started":"2022-11-24T00:38:14.221876Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","FaceCNN                                  [1, 10]                   --\n","├─Sequential: 1-1                        [1, 64]                   --\n","│    └─Conv2d: 2-1                       [1, 64, 123, 123]         9,472\n","│    └─BatchNorm2d: 2-2                  [1, 64, 123, 123]         128\n","│    └─ReLU: 2-3                         [1, 64, 123, 123]         --\n","│    └─MaxPool2d: 2-4                    [1, 64, 61, 61]           --\n","│    └─Dropout: 2-5                      [1, 64, 61, 61]           --\n","│    └─Conv2d: 2-6                       [1, 128, 61, 61]          73,856\n","│    └─BatchNorm2d: 2-7                  [1, 128, 61, 61]          256\n","│    └─ReLU: 2-8                         [1, 128, 61, 61]          --\n","│    └─MaxPool2d: 2-9                    [1, 128, 30, 30]          --\n","│    └─Dropout: 2-10                     [1, 128, 30, 30]          --\n","│    └─Conv2d: 2-11                      [1, 256, 30, 30]          295,168\n","│    └─BatchNorm2d: 2-12                 [1, 256, 30, 30]          512\n","│    └─ReLU: 2-13                        [1, 256, 30, 30]          --\n","│    └─MaxPool2d: 2-14                   [1, 256, 15, 15]          --\n","│    └─Dropout: 2-15                     [1, 256, 15, 15]          --\n","│    └─Conv2d: 2-16                      [1, 64, 15, 15]           147,520\n","│    └─BatchNorm2d: 2-17                 [1, 64, 15, 15]           128\n","│    └─ReLU: 2-18                        [1, 64, 15, 15]           --\n","│    └─Dropout: 2-19                     [1, 64, 15, 15]           --\n","│    └─Flatten: 2-20                     [1, 14400]                --\n","│    └─Linear: 2-21                      [1, 1024]                 14,746,624\n","│    └─ReLU: 2-22                        [1, 1024]                 --\n","│    └─Dropout: 2-23                     [1, 1024]                 --\n","│    └─Linear: 2-24                      [1, 64]                   65,600\n","│    └─ReLU: 2-25                        [1, 64]                   --\n","├─Sequential: 1-2                        [1, 10]                   --\n","│    └─Dropout: 2-26                     [1, 64]                   --\n","│    └─Linear: 2-27                      [1, 10]                   650\n","==========================================================================================\n","Total params: 15,339,914\n","Trainable params: 15,339,914\n","Non-trainable params: 0\n","Total mult-adds (M): 731.78\n","==========================================================================================\n","Input size (MB): 0.75\n","Forward/backward pass size (MB): 27.04\n","Params size (MB): 61.36\n","Estimated Total Size (MB): 89.15\n","==========================================================================================\n"]}],"source":["num_input_channels = 3\n","model = FaceCNN(num_input_channels=num_input_channels, num_classes=len(list_people)).to(device)\n","print(summary(model, input_size=(dataloader_kwargs['batch_size'], num_input_channels, 250, 250)))\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","num_epochs = 30"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:38:14.409820Z","iopub.status.busy":"2022-11-24T00:38:14.408970Z","iopub.status.idle":"2022-11-24T00:38:14.416473Z","shell.execute_reply":"2022-11-24T00:38:14.415512Z","shell.execute_reply.started":"2022-11-24T00:38:14.409780Z"},"trusted":true},"outputs":[],"source":["def evaluate(loader, model):\n","\n","    model.eval()\n","\n","    score = 0\n","    cnt = 0\n","\n","    with torch.no_grad():       # not training, so no need to calculate gradients\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","            output, _ = model(inputs)\n","            _, pred = torch.max(output.data, 1)\n","            score += float(torch.sum(pred==labels.data))\n","            cnt += data[0].shape[0]\n","\n","    return score/cnt"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:38:14.585625Z","iopub.status.busy":"2022-11-24T00:38:14.585266Z","iopub.status.idle":"2022-11-24T00:38:14.597415Z","shell.execute_reply":"2022-11-24T00:38:14.596333Z","shell.execute_reply.started":"2022-11-24T00:38:14.585595Z"},"trusted":true},"outputs":[],"source":["def train():\n","    best_acc = 0.0\n","    \n","    for epoch in range(num_epochs):\n","        train_score = 0\n","        cnt = 0\n","        CE_loss = 0\n","        triplet_loss = 0\n","\n","        model.train()\n","        \n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","\n","            optimizer.zero_grad()\n","            \n","            outputs,_ = model(inputs)\n","            \n","            # print(outputs, labels)\n","\n","            loss = loss_fn(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            CE_loss += loss.item()\n","\n","            _, preds = torch.max(outputs.data, 1)\n","            train_score += float(torch.sum(preds==labels.data))\n","            cnt += inputs.shape[0]\n","\n","            # print(preds, labels)\n","\n","        for inputs, labels in train_loader_triplet:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","            optimizer.zero_grad()\n","            outputs, encoded = model(inputs)\n","            loss = triplet_loss_fn(encoded, labels, len(list_people))\n","            loss.backward()\n","            optimizer.step()\n","            \n","            triplet_loss += loss.item()\n","\n","        train_acc = train_score/cnt\n","        val_acc = evaluate(val_loader, model)\n","        \n","        print(\"Epoch:\", epoch, \"\\tLoss:\", CE_loss, triplet_loss, \"\\tTraining Acc:\", train_acc, \"\\tVal Acc:\", val_acc)\n","\n","        if val_acc > best_acc:\n","            torch.save(model.state_dict(),'best.model')\n","            best_acc = val_acc"]},{"cell_type":"code","execution_count":111,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:38:14.870253Z","iopub.status.busy":"2022-11-24T00:38:14.869854Z","iopub.status.idle":"2022-11-24T00:44:19.660727Z","shell.execute_reply":"2022-11-24T00:44:19.659374Z","shell.execute_reply.started":"2022-11-24T00:38:14.870221Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 \tLoss: 1523.5315465927124 3.576771288542659 \tTraining Acc: 0.09696969696969697 \tVal Acc: 0.13333333333333333\n","Epoch: 1 \tLoss: 1480.5981893539429 7.036555926315486 \tTraining Acc: 0.16363636363636364 \tVal Acc: 0.2111111111111111\n","Epoch: 2 \tLoss: 1388.423449397087 8.345587398856878 \tTraining Acc: 0.20454545454545456 \tVal Acc: 0.3055555555555556\n","Epoch: 3 \tLoss: 1273.9857878684998 7.455293735489249 \tTraining Acc: 0.28484848484848485 \tVal Acc: 0.29444444444444445\n","Epoch: 4 \tLoss: 1154.534344483167 10.415365964407101 \tTraining Acc: 0.34393939393939393 \tVal Acc: 0.25555555555555554\n","Epoch: 5 \tLoss: 1047.3524520546198 13.149000030942261 \tTraining Acc: 0.4090909090909091 \tVal Acc: 0.48333333333333334\n","Epoch: 6 \tLoss: 957.3268567174673 10.303598511964083 \tTraining Acc: 0.47575757575757577 \tVal Acc: 0.4388888888888889\n","Epoch: 7 \tLoss: 870.0268783867359 10.868931866018102 \tTraining Acc: 0.503030303030303 \tVal Acc: 0.4722222222222222\n","Epoch: 8 \tLoss: 784.0191351852845 9.920111494488083 \tTraining Acc: 0.5712121212121212 \tVal Acc: 0.5722222222222222\n","Epoch: 9 \tLoss: 726.4030978577211 8.74607165181078 \tTraining Acc: 0.5954545454545455 \tVal Acc: 0.5222222222222223\n","Epoch: 10 \tLoss: 648.8383911615238 7.003953116945922 \tTraining Acc: 0.6333333333333333 \tVal Acc: 0.5777777777777777\n","Epoch: 11 \tLoss: 539.6153651204659 4.386305276304483 \tTraining Acc: 0.7333333333333333 \tVal Acc: 0.6611111111111111\n","Epoch: 12 \tLoss: 489.7847711899085 5.951085742563009 \tTraining Acc: 0.7348484848484849 \tVal Acc: 0.6666666666666666\n","Epoch: 13 \tLoss: 432.2068381062236 4.255612261593342 \tTraining Acc: 0.7757575757575758 \tVal Acc: 0.6722222222222223\n","Epoch: 14 \tLoss: 343.74397443032285 9.914098668843508 \tTraining Acc: 0.8196969696969697 \tVal Acc: 0.6666666666666666\n","Epoch: 15 \tLoss: 303.559323878123 8.046713775023818 \tTraining Acc: 0.8515151515151516 \tVal Acc: 0.6388888888888888\n","Epoch: 16 \tLoss: 275.3211619486791 3.6582124223932624 \tTraining Acc: 0.8712121212121212 \tVal Acc: 0.75\n","Epoch: 17 \tLoss: 241.8037844949895 1.797354519367218 \tTraining Acc: 0.8590909090909091 \tVal Acc: 0.75\n","Epoch: 18 \tLoss: 184.26001776331145 3.4133712593466043 \tTraining Acc: 0.9121212121212121 \tVal Acc: 0.7611111111111111\n","Epoch: 19 \tLoss: 192.51421108496288 4.5144732892513275 \tTraining Acc: 0.9030303030303031 \tVal Acc: 0.6888888888888889\n","Epoch: 20 \tLoss: 149.83255621286182 8.019566843286157 \tTraining Acc: 0.9318181818181818 \tVal Acc: 0.7333333333333333\n","Epoch: 21 \tLoss: 144.79257992344526 1.2211938351392746 \tTraining Acc: 0.9378787878787879 \tVal Acc: 0.75\n","Epoch: 22 \tLoss: 143.5872083009824 2.038029834628105 \tTraining Acc: 0.9363636363636364 \tVal Acc: 0.7777777777777778\n","Epoch: 23 \tLoss: 123.919953769438 1.6883821487426758 \tTraining Acc: 0.9484848484848485 \tVal Acc: 0.7944444444444444\n","Epoch: 24 \tLoss: 98.82284028425221 4.898437852039933 \tTraining Acc: 0.9545454545454546 \tVal Acc: 0.7722222222222223\n","Epoch: 25 \tLoss: 83.99055815203701 1.9400578290224075 \tTraining Acc: 0.9681818181818181 \tVal Acc: 0.8\n","Epoch: 26 \tLoss: 61.44266167897944 2.3215142358094454 \tTraining Acc: 0.9818181818181818 \tVal Acc: 0.7944444444444444\n","Epoch: 27 \tLoss: 71.44229046234102 0.5808688141405582 \tTraining Acc: 0.9696969696969697 \tVal Acc: 0.8055555555555556\n","Epoch: 28 \tLoss: 64.90646457042854 1.1003028750419617 \tTraining Acc: 0.9651515151515152 \tVal Acc: 0.8055555555555556\n","Epoch: 29 \tLoss: 49.41264337577971 0.007978972978889942 \tTraining Acc: 0.9833333333333333 \tVal Acc: 0.8\n"]}],"source":["train()"]},{"cell_type":"code","execution_count":112,"metadata":{"execution":{"iopub.execute_input":"2022-11-24T00:44:19.666441Z","iopub.status.busy":"2022-11-24T00:44:19.663824Z","iopub.status.idle":"2022-11-24T00:44:20.968900Z","shell.execute_reply":"2022-11-24T00:44:20.967800Z","shell.execute_reply.started":"2022-11-24T00:44:19.666397Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8909090909090909\n"]}],"source":["model.load_state_dict(torch.load('best.model'))\n","model.eval()\n","score = 0\n","cnt = 0\n","\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        output, encoded = model(inputs)\n","        _, pred = torch.max(output.data, 1)\n","        score += float(torch.sum(pred==labels.data))\n","        cnt += data[0].shape[0]\n","\n","print(score/cnt)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load('best.model'))\n","model.eval()\n","\n","arr_encoder = torch.zeros((2*data_test.shape[0],64))\n","arr_labels = torch.zeros((2*data_test.shape[0]))\n","idx = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        output, encoded = model(inputs)\n","        arr_encoder[idx] = encoded\n","        arr_labels[idx] = labels\n","        idx += 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for c in range(num_ppl):\n","    p = arr_encoder[arr_labels==c]\n","    n = arr_encoder[~(arr_labels==c)]\n","    p_self = torch.mean(torch.sum((p[:,None,:]-p[None,:,:])**2, dim=2))\n","    p_n = torch.mean(torch.sum((p[:,None,:]-n[None,:,:])**2, dim=2))\n","    print(f\"class : {c} closeness ratio : {p_self/p_n}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Adversarial attack"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import math\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Generator, self).__init__()\n","        self.noise = nn.Parameter(torch.randn(size = input_shape))\n","        # We attempt a simple strategy of adding constant noise to each image\n","\n","    def forward(self, input):\n","        out = input + self.noise\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.load_state_dict(torch.load('best.model'))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["generator = Generator([1,3,250,250])\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(generator.parameters(), lr=1e-3, weight_decay=1e-3)"]},{"cell_type":"markdown","metadata":{},"source":["### l2 regularized"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def regularizer(image1, image2, lam = 1):\n","    return torch.mean((image1-image2)**2)*lam"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_epochs = 6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(num_epochs):\n","    train_score = 0\n","    cnt = 0\n","    train_loss = 0\n","    generator.train()\n","    \n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        optimizer.zero_grad()\n","        gen = generator(inputs)\n","        outputs,_ = model(gen)\n","        \n","        # print(outputs, labels)\n","        loss = -loss_fn(outputs, labels) + regularizer(inputs, gen, lam=2*1e4)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, preds = torch.max(outputs.data, 1)\n","        train_score += float(torch.sum(preds==labels.data))\n","        cnt += inputs.shape[0]\n","        \n","    train_acc = train_score/cnt\n","    score = 0\n","    cnt = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","            output, encoded = model(generator(inputs))\n","            _, pred = torch.max(output.data, 1)\n","            score += float(torch.sum(pred==labels.data))\n","            cnt += data[0].shape[0]\n","\n","    val_acc = (score/cnt)\n","    print(\"Epoch:\", epoch, \"\\tLoss:\", train_loss, \"\\tTraining Acc:\", train_acc, \"\\tValidation Acc:\", val_acc)\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            plt.figure()\n","            f, axarr = plt.subplots(1,2)\n","            axarr[0].imshow(inputs[0].permute(1, 2, 0))\n","            axarr[1].imshow(generator(inputs)[0].permute(1, 2, 0).detach().numpy())\n","            plt.show(block=True)\n","            break\n"]},{"cell_type":"code","execution_count":210,"metadata":{},"outputs":[],"source":["torch.save(generator.state_dict(),'generator2')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["score = 0\n","cnt = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        output, encoded = model(generator(inputs))\n","        _, pred = torch.max(output.data, 1)\n","        score += float(torch.sum(pred==labels.data))\n","        cnt += data[0].shape[0]\n","\n","print(\"test acc:\", score/cnt)\n","for inputs, labels in test_loader:\n","    plt.figure()\n","    f, axarr = plt.subplots(1,2)\n","    axarr[0].imshow(inputs[0].permute(1, 2, 0))\n","    axarr[1].imshow(generator(inputs)[0].permute(1, 2, 0).detach().numpy())\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["### l1 regularized"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["def regularizer(image1, image2, lam = 1):\n","    return torch.mean(torch.abs(image1-image2))*lam"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["num_epochs = 6"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for epoch in range(num_epochs):\n","    train_score = 0\n","    cnt = 0\n","    train_loss = 0\n","    generator.train()\n","    \n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        optimizer.zero_grad()\n","        gen = generator(inputs)\n","        outputs,_ = model(gen)\n","        \n","        # print(outputs, labels)\n","        loss = -loss_fn(outputs, labels) + regularizer(inputs, gen, lam=1e2)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        train_loss += loss.item()\n","        _, preds = torch.max(outputs.data, 1)\n","        train_score += float(torch.sum(preds==labels.data))\n","        cnt += inputs.shape[0]\n","        \n","    train_acc = train_score/cnt\n","    score = 0\n","    cnt = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","            output, encoded = model(generator(inputs))\n","            _, pred = torch.max(output.data, 1)\n","            score += float(torch.sum(pred==labels.data))\n","            cnt += data[0].shape[0]\n","\n","    val_acc = (score/cnt)\n","    print(\"Epoch:\", epoch, \"\\tLoss:\", train_loss, \"\\tTraining Acc:\", train_acc, \"\\tValidation Acc:\", val_acc)\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            plt.figure()\n","            f, axarr = plt.subplots(1,2)\n","            axarr[0].imshow(inputs[0].permute(1, 2, 0))\n","            axarr[1].imshow(generator(inputs)[0].permute(1, 2, 0).detach().numpy())\n","            plt.show(block=True)\n","            break"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["torch.save(generator.state_dict(),'generator1')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["score = 0\n","cnt = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device, non_blocking=non_blocking), labels.to(device, non_blocking=non_blocking)\n","        output, encoded = model(generator(inputs))\n","        _, pred = torch.max(output.data, 1)\n","        score += float(torch.sum(pred==labels.data))\n","        cnt += data[0].shape[0]\n","\n","print(\"test acc:\", score/cnt)\n","for inputs, labels in test_loader:\n","    plt.figure()\n","    f, axarr = plt.subplots(1,2)\n","    axarr[0].imshow(inputs[0].permute(1, 2, 0))\n","    axarr[1].imshow(generator(inputs)[0].permute(1, 2, 0).detach().numpy())\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["### Observations\n","l2 regularized attacks seem to fair better than l1 regularized at visual similarity i.e. need to add \"less\" noise for similar reduction in model accuracy"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"vscode":{"interpreter":{"hash":"8ffc022e556dbf9e4707e0813792d41f1f0550f46106b79e6c9a363a1f17dd45"}}},"nbformat":4,"nbformat_minor":4}
